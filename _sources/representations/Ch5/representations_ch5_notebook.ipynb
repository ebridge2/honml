{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "45016ba3",
      "cell_type": "markdown",
      "source": "(ch5:code_repr)=\n# Code Reproducibility",
      "metadata": {}
    },
    {
      "id": "9b56d517",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import er_np\nimport numpy as np\n\np = 0.3\nA = er_np(n=50, p=p)",
      "outputs": []
    },
    {
      "id": "71066d1b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.models import EREstimator\n\nmodel = EREstimator(directed=False, loops=False)\nmodel.fit(A)\n# obtain the estimate from the fit model\nphat = model.p_",
      "outputs": []
    },
    {
      "id": "88e1742b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "print(\"Difference between phat and p: {:.3f}\".format(phat - p))",
      "outputs": []
    },
    {
      "id": "75df1e95",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import sbm\n\nn = [50, 50]\nB = np.array([[0.6, 0.1], \n              [0.1, 0.4]])\n\nA, z = sbm(n=n, p=B, return_labels=True)",
      "outputs": []
    },
    {
      "id": "d13ecf36",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.models import SBMEstimator\nfrom graphbook_code import heatmap\n\nmodel = SBMEstimator(directed=False, loops=False)\nmodel.fit(A, y=z)\nBhat = model.block_p_\n\n# plot the block matrix vs estimate\nheatmap(B, title=\"$B$ true block matrix\", vmin=0, vmax=1, annot=True)\nheatmap(Bhat, title=r\"$\\hat B$ estimate of block matrix\", vmin=0, vmax=1, annot=True)\nheatmap(np.abs(Bhat - B), title=r\"$|\\hat B - B|$\", vmin=0, vmax=1, annot=True)",
      "outputs": []
    },
    {
      "id": "05a4fbe0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import sbm\nfrom graphbook_code import generate_sbm_pmtx, lpm_from_sbm\nimport numpy as np\n\nn = 100\n# construct the block matrix B as described above\nB = np.array([[0.6, 0.1], \n              [0.1, 0.4]])\n\n# sample a graph from SBM_{100}(tau, B)\nnp.random.seed(0)\nA, zs = sbm(n=[n//2, n//2], p=B, return_labels=True)\n\nX = lpm_from_sbm(zs, B)\nP = generate_sbm_pmtx(zs, B)",
      "outputs": []
    },
    {
      "id": "4ea078c1",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed as ase\n\nd = 2  # the latent dimensionality\n# estimate the latent position matrix with ase\nXhat = ase(n_components=d, svd_seed=0).fit_transform(A)",
      "outputs": []
    },
    {
      "id": "26789f9c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "Phat = Xhat @ Xhat.transpose()",
      "outputs": []
    },
    {
      "id": "51cc98f0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "vtx_perm = np.random.choice(n, size=n, replace=False)\n\n# reorder the adjacency matrix\nAperm = A[tuple([vtx_perm])] [:,vtx_perm]\n# reorder the community assignment vector\nzperm = np.array(zs)[vtx_perm]\n\n# compute the estimated latent positions using the\n# permuted adjacency matrix\nXhat_perm = ase(n_components=2).fit_transform(Aperm)",
      "outputs": []
    },
    {
      "id": "65470c97",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.plot import pairplot\n\npairplot(Xhat, title=r\"Pairs plot of $\\hat X$\")",
      "outputs": []
    },
    {
      "id": "519c8d4e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "fig = pairplot(Xhat_perm, labels=zperm, legend_name = \"Community\",\n             title=r\"Pairs plot of $\\widehat X$ with community annotation\",\n             dig_kind=\"hist\")",
      "outputs": []
    },
    {
      "id": "81762014",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from scipy.spatial import distance_matrix\n\nD = distance_matrix(Xhat, Xhat)",
      "outputs": []
    },
    {
      "id": "6d6879ec",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nfrom graphbook_code import dcsbm\n\nnk = 150\nz = np.repeat([1,2], nk)\nB = np.array([[0.6, 0.2], [0.2, 0.4]])\ntheta = np.tile(6**np.linspace(0, -1, nk), 2)\nnp.random.seed(0)\nA, P = dcsbm(z, theta, B, return_prob=True)",
      "outputs": []
    },
    {
      "id": "720df714",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed as ase\nfrom scipy.spatial import distance_matrix\n\nd = 2  # the latent dimensionality\n# estimate the latent position matrix with ase\nXhat = ase(n_components=d, svd_seed=0).fit_transform(A)\n# compute the distance matrix\nD = distance_matrix(Xhat, Xhat)",
      "outputs": []
    },
    {
      "id": "36d37d3d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "Xhat_rescaled = Xhat / theta[:,None]\nD_rescaled = distance_matrix(Xhat_rescaled, Xhat_rescaled)",
      "outputs": []
    },
    {
      "id": "57de6952",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import LaplacianSpectralEmbed as lse\n\nd = 2  # embed into two dimensions\nXhat_lapl = lse(n_components=d, svd_seed=0).fit_transform(A)\nD_lapl = distance_matrix(Xhat_lapl, Xhat_lapl)",
      "outputs": []
    },
    {
      "id": "5b4d3fe3",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import seaborn as sns\nimport pandas as pd\n\n# compute the degrees for each node, using the\n# row-sums of the network\ndegrees = A.sum(axis = 0)\n\n# plot the degree histogram\ndf = pd.DataFrame({\"Node degree\" : degrees, \"Community\": z})\nsns.histplot(data=df, x=\"Node degree\", bins=20, color=\"black\")",
      "outputs": []
    },
    {
      "id": "88e77eca",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "Asbm = sbm([nk, nk], B)\n\n# row-sums of the network\ndegrees_sbm = Asbm.sum(axis = 0)",
      "outputs": []
    },
    {
      "id": "42be707e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import sbm\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\n\nn = 100  # the number of nodes\nM = 8  # the total number of networks\n# human brains have homophilic block structure\nBhuman = np.array([[0.2, 0.02], [0.02, 0.2]])\n# alien brains have a core-periphery block structure\nBalien = np.array([[0.4, 0.2], [0.2, 0.1]])\n\n# set seed for reproducibility\nnp.random.seed(0)\n\n# generate 4 human and 4 alien brain networks\nA_humans = [sbm([n // 2, n // 2], Bhuman) for i in range(M // 2)]\nA_aliens = [sbm([n // 2, n // 2], Balien) for i in range(M // 2)]\n# concatenate list of human and alien networks\nnetworks = A_humans + A_aliens\n\n# 1 = left hemisphere, 2 = right hemisphere for node communities\nle = LabelEncoder()\nlabels = np.repeat([\"L\", \"R\"], n//2)\nzs = le.fit_transform(labels) + 1",
      "outputs": []
    },
    {
      "id": "f772dd87",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed as ase\n\n# embed the first network\nXhat = ase(n_components=2, svd_seed=0).fit_transform(A_humans[0])",
      "outputs": []
    },
    {
      "id": "21bb2281",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# a rotation by 90 degrees\nW = np.array([[0, -1], [1, 0]])\nYhat = Xhat @ W",
      "outputs": []
    },
    {
      "id": "4cb96df7",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# check that probability matrix is the same\nnp.allclose(Yhat @ Yhat.transpose(), Xhat @ Xhat.transpose())\n# returns True",
      "outputs": []
    },
    {
      "id": "e3f9d928",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# a reflection across first latent dimension\nWp = np.array([[-1, 0], [0, 1]])\nZhat = Xhat @ Wp\n# check that the probability matrix is the same\n# check that probability matrix is the same\nnp.allclose(Zhat @ Zhat.transpose(), Xhat @ Xhat.transpose())\n# returns True",
      "outputs": []
    },
    {
      "id": "2dc87f90",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# embed the third human network\nXhat3 = ase(n_components=2, svd_seed=0).fit_transform(A_humans[3])",
      "outputs": []
    },
    {
      "id": "3c2a3c97",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# embed the first alien network\nXhat_alien = ase(n_components=2, svd_seed=0).fit_transform(A_aliens[0])\n\n# compute frob norm between first human and third human net\n# estimated latent positions\ndist_firsthum_thirdhum = np.linalg.norm(Xhat - Xhat3, ord=\"fro\")\nprint(\"Frob. norm(first human, third human) = {:3f}\".format(dist_firsthum_thirdhum))\n# Frob. norm(first human, third human) = 8.798482\n\n# compute frob norm between first human and first alien net\n# estimated latent positions\ndist_firsthum_alien = np.linalg.norm(Xhat - Xhat_alien, ord=\"fro\")\nprint(\"Frob. norm(first human, alien) = {:3f}\".format(dist_firsthum_alien))\n# Frob. norm(first human, alien) = 5.991560",
      "outputs": []
    },
    {
      "id": "724b26e5",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import MultipleASE as mase\n\n# Use mase to embed everything\nmase = mase(n_components=2, svd_seed=0)\n# fit_transform on the human and alien networks simultaneously\nlatents_mase = mase.fit_transform(networks)",
      "outputs": []
    },
    {
      "id": "565ffcc8",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed as ase\n\ndhat = int(np.ceil(np.log2(n)))\n# spectrally embed each network into ceil(log2(n)) dimensions with ASE\nseparate_embeddings = [ase(n_components=dhat, svd_seed=0).fit_transform(network) for network in networks]",
      "outputs": []
    },
    {
      "id": "0114131f",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Concatenate the embeddings horizontally into a single n x Md matrix\njoint_matrix = np.hstack(separate_embeddings)",
      "outputs": []
    },
    {
      "id": "e4c205c6",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def unscaled_embed(X, d, seed=0):\n    np.random.seed(seed)\n    U, s, Vt = np.linalg.svd(X)\n    return U[:,0:d]\n\nShat = unscaled_embed(joint_matrix, 2)",
      "outputs": []
    },
    {
      "id": "a71213cc",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# stack the networks into a numpy array\nAs_ar = np.asarray(networks)\n# compute the scores\nscores = Shat.T @ As_ar @ Shat",
      "outputs": []
    },
    {
      "id": "568f0986",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import generate_sbm_pmtx\n\nPhum = generate_sbm_pmtx(zs, Bhuman)\nPalien = generate_sbm_pmtx(zs, Balien)\nPests = Shat @ scores @ Shat.T",
      "outputs": []
    },
    {
      "id": "129b88b8",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import MultipleASE as mase\n\nd = 2\nmase_embedder = mase(n_components=d)\n# obtain an estimate of the shared latent positions\nShat = mase_embedder.fit_transform(networks)\n# obtain an estimate of the scores\nRhat_hum1 = mase_embedder.scores_[0]\n# obtain an estimate of the probability matrix for the first human\nPhat_hum1 = Shat @ mase_embedder.scores_[0] @ Shat.T",
      "outputs": []
    },
    {
      "id": "f8eb372d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "omni_ex = np.block(\n    [[networks[0], (networks[0]+networks[1])/2],\n     [(networks[1]+networks[0])/2, networks[1]]]\n)",
      "outputs": []
    },
    {
      "id": "96b49721",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed.omni import _get_omni_matrix\nomni_mtx = _get_omni_matrix(networks)",
      "outputs": []
    },
    {
      "id": "bfcc48f8",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed as ase\n\ndhat = int(np.ceil(np.log2(n)))\nXhat_omni = ase(n_components=dhat, svd_seed=0).fit_transform(omni_mtx)",
      "outputs": []
    },
    {
      "id": "d4a54b1f",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "M = len(networks)\nn = len(networks[0])\n\n# obtain an M x n x d tensor\nXhat_tensor = Xhat_omni.reshape(M, n, -1)\n# the estimated latent positions for the first network\nXhat_human1 = Xhat_tensor[0,:,:]",
      "outputs": []
    },
    {
      "id": "701b1011",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import OmnibusEmbed as omni\n\n# obtain a tensor of the estimated latent positions\nXhat_tensor = omni(n_components=int(np.log2(n)), svd_seed=0).fit_transform(networks)\n# obtain the estimated latent positions for the first human\n# network\nXhat_human1 = Xhat_tensor[0,:,:]",
      "outputs": []
    },
    {
      "id": "ad56f93f",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "Phat_hum1 = Xhat_human1 @ Xhat_human1.T",
      "outputs": []
    },
    {
      "id": "22003423",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import sbm\nimport numpy as np\n\nn = 200  # total number of nodes\n# first two communities are the ``core'' pages for statistics\n# and computer science, and second two are the ``peripheral'' pages\n# for statistics and computer science.\nB = np.array([[.4, .3, .05, .05],\n              [.3, .4, .05, .05],\n              [.05, .05, .05, .02],\n              [.05, .05, .02, .05]])\n\n# make the stochastic block model\nnp.random.seed(0)\nA, labels = sbm([n // 4, n // 4, n // 4, n // 4], B, return_labels=True)\n# generate labels for core/periphery\nco_per_labels = np.repeat([\"Core\", \"Periphery\"], repeats=n//2)\n# generate labels for statistics/CS.\nst_cs_labels = np.repeat([\"Stat\", \"CS\", \"Stat\", \"CS\"], repeats=n//4)",
      "outputs": []
    },
    {
      "id": "f1ed5fcd",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "trial = []\nfor label in st_cs_labels:\n    if \"Stat\" in label:\n        # if the page is a statistics page, there is a 50% chance\n        # of citing each of the scholars\n        trial.append(np.random.binomial(1, 0.5, size=20))\n    else:\n        # if the page is a CS page, there is a 5% chance of citing\n        # each of the scholars\n        trial.append(np.random.binomial(1, 0.05, size=20))\nY = np.vstack(trial)",
      "outputs": []
    },
    {
      "id": "876361c8",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def embed(X, d=2, seed=0):\n    \"\"\"\n    A function to embed a matrix.\n    \"\"\"\n    np.random.seed(seed)\n    Lambda, V = np.linalg.eig(X)\n    return V[:, 0:d] @ np.diag(np.sqrt(np.abs(Lambda[0:d])))\n\ndef pca(X, d=2, seed=0):\n    \"\"\"\n    A function to perform a pca on a data matrix.\n    \"\"\"\n    X_centered = X - np.mean(X, axis=0)\n    return embed(X_centered @ X_centered.T, d=d, seed=seed)\n\nY_embedded = pca(Y, d=2)",
      "outputs": []
    },
    {
      "id": "39f7850e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.utils import to_laplacian\n\n# compute the network Laplacian\nL_wiki = to_laplacian(A, form=\"DAD\")\n# log transform, strictly for visualization purposes\nL_wiki_logxfm = np.log(L_wiki + np.min(L_wiki[L_wiki > 0])/np.exp(1))\n\n# compute the node similarity matrix\nY_sim = Y @ Y.T",
      "outputs": []
    },
    {
      "id": "a1e5fe13",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed as ase\n\ndef case(A, Y, weight=0, d=2, tau=0, seed=0):\n    \"\"\"\n    A function for performing case.\n    \"\"\"\n    # compute the laplacian\n    L = to_laplacian(A, form=\"R-DAD\", regularizer=tau)\n    YYt = Y @ Y.T\n    return ase(n_components=2, svd_seed=seed).fit_transform(L + weight*YYt)\n\nembedded = case(A, Y, weight=.002)",
      "outputs": []
    },
    {
      "id": "8ee1f6b0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import CovariateAssistedEmbed as case\n\nembedding = case(alpha=None, n_components=2).fit_transform(A, covariates=Y)",
      "outputs": []
    },
    {
      "id": "1a57fccd",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "embedding = case(assortative=False, n_components=2).fit_transform(A, covariates=Y)",
      "outputs": []
    },
    {
      "id": "df5191d1",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import sbm\nimport numpy as np\n\n# block matrix\nn = 100\nB = np.array([[0.6, 0.2], [0.2, 0.4]])\n# network sample\nnp.random.seed(0)\nA, z = sbm([n // 2, n // 2], B, return_labels=True)",
      "outputs": []
    },
    {
      "id": "733a2ef3",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from scipy.linalg import svdvals\n\n# use scipy to obtain the singular values\ns = svdvals(A)",
      "outputs": []
    },
    {
      "id": "ae5aa7e1",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from pandas import DataFrame\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\ndef plot_scree(svs, title=\"\", ax=None):\n    \"\"\"\n    A utility to plot the scree plot for a list of singular values\n    svs.\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots(1,1, figsize=(10, 4))\n    sv_dat = DataFrame({\"Singular Value\": svs, \"Dimension\": range(1, len(svs) + 1)})\n    sns.scatterplot(data=sv_dat, x=\"Dimension\", y=\"Singular Value\", ax=ax)\n    sns.lineplot(data=sv_dat, x=\"Dimension\", y=\"Singular Value\", ax=ax)\n    ax.set_xlim([0.5, len(s)])\n    ax.set_title(title)\n\nplot_scree(s, title=\"Scree plot of $L$\")",
      "outputs": []
    },
    {
      "id": "4395addd",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed as ase\n\n# use automatic elbow selection\nXhat_auto = ase(svd_seed=0).fit_transform(A)",
      "outputs": []
    },
    {
      "id": "f7537983",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed as ase\nfrom scipy.spatial import distance_matrix\n\nnk = 50  # the number of nodes in each community\nB_indef = np.array([[.1, .5], [.5, .2]])\nnp.random.seed(0)\nA_dis, z = sbm([nk, nk], B_indef, return_labels=True)\nXhat = ase(n_components=2, svd_seed=0).fit_transform(A_dis)\nD = distance_matrix(Xhat, Xhat)",
      "outputs": []
    }
  ]
}