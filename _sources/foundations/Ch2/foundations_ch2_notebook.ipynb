{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a4bbcc-dcec-4eed-8e87-182d8a40a170",
   "metadata": {},
   "source": [
    "# Code Reproducibility: Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab262c0a-5b13-4792-9e9e-10abfa29f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "from graspologic.utils import import_edgelist\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# the AWS bucket the data is stored in\n",
    "BUCKET_ROOT = \"open-neurodata\"\n",
    "parcellation = \"Schaefer400\"\n",
    "FMRI_PREFIX = \"m2g/Functional/BNU1-11-12-20-m2g-func/Connectomes/\" + parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz/\"\n",
    "FMRI_PATH = os.path.join(\"datasets\", \"fmri\")  # the output folder\n",
    "DS_KEY = \"abs_edgelist\"  # correlation matrices for the networks to exclude\n",
    "\n",
    "def fetch_fmri_data(bucket=BUCKET_ROOT, fmri_prefix=FMRI_PREFIX,\n",
    "                    output=FMRI_PATH, name=DS_KEY):\n",
    "    \"\"\"\n",
    "    A function to fetch fMRI connectomes from AWS S3.\n",
    "    \"\"\"\n",
    "    # check that output directory exists\n",
    "    if not os.path.isdir(FMRI_PATH):\n",
    "        os.makedirs(FMRI_PATH)\n",
    "    # start boto3 session anonymously\n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    # obtain the filenames\n",
    "    bucket_conts = s3.list_objects(Bucket=bucket, \n",
    "                    Prefix=fmri_prefix)[\"Contents\"]\n",
    "    for s3_key in tqdm(bucket_conts):\n",
    "        # get the filename\n",
    "        s3_object = s3_key['Key']\n",
    "        # verify that we are grabbing the right file\n",
    "        if name not in s3_object:\n",
    "            op_fname = os.path.join(FMRI_PATH, str(s3_object.split('/')[-1]))\n",
    "            if not os.path.exists(op_fname):\n",
    "                s3.download_file(bucket, s3_object, op_fname)\n",
    "\n",
    "def read_fmri_data(path=FMRI_PATH):\n",
    "    \"\"\"\n",
    "    A function which loads the connectomes as adjacency matrices.\n",
    "    \"\"\"\n",
    "    fnames = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    # sort for consistency\n",
    "    fnames.sort()\n",
    "    # import edgelists with graspologic\n",
    "    # edgelists will be all of the files that end in a csv\n",
    "    networks = [import_edgelist(fname) for fname in tqdm(fnames)]\n",
    "    return np.stack(networks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80634695",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_fmri_data()\n",
    "As = read_fmri_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphbook_code import heatmap\n",
    "\n",
    "A = As[0]\n",
    "ax = heatmap(A, vmin=-1, vmax=1, title=\"Heatmap of Functional Connectome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb964401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = sns.histplot(A.flatten(), bins=50)\n",
    "ax.set_xlabel(\"Edge weight\")\n",
    "ax.set_title(\"Histogram of functional connectome edge-weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_isolates(A):\n",
    "    \"\"\"\n",
    "    A function which removes isolated nodes from the \n",
    "    adjacency matrix A.\n",
    "    \"\"\"\n",
    "    degree = A.sum(axis=0)  # sum along the rows to obtain the node degree\n",
    "    out_degree = A.sum(axis=1)\n",
    "    A_purged = A[~(degree == 0),:]\n",
    "    A_purged = A_purged[:,~(degree == 0)]\n",
    "    print(\"Purging {:d} nodes...\".format((degree == 0).sum()))\n",
    "    return A_purged\n",
    "    \n",
    "A = remove_isolates(A)\n",
    "# Purging 0 nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from graphbook_code import heatmap\n",
    "\n",
    "A_abs = np.abs(A)\n",
    "fig, axs = plt.subplots(1,3, figsize=(21, 6))\n",
    "heatmap(A, ax=axs[0], title=\"Human Connectome, Raw\", vmin=np.min(A), vmax=1)\n",
    "heatmap(A_abs, ax=axs[1], title=\"Human Connectome, Absolute\", vmin=np.min(A), vmax=1)\n",
    "heatmap(A_abs - A, ax=axs[2], title=\"Difference(Absolute - Raw)\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd474185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class CleanData(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Cleaning data...\")\n",
    "        Acleaned = remove_isolates(X)\n",
    "        A_abs_cl = np.abs(Acleaned)\n",
    "        self.A_ = A_abs_cl\n",
    "        return self.A_\n",
    "\n",
    "data_cleaner = CleanData()\n",
    "A_clean = data_cleaner.transform(A)\n",
    "# Cleaning data...\n",
    "# Purging 0 nodes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import binarize\n",
    "\n",
    "threshold = 0.4\n",
    "A_bin = binarize(A_clean > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b98c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import pass_to_ranks\n",
    "\n",
    "A_ptr = pass_to_ranks(A_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379767e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "sns.histplot(A_clean[A_clean > 0].flatten(), ax=axs[0], color=\"gray\")\n",
    "axs[0].set_xlabel(\"Edge weight\")\n",
    "axs[0].set_title(\"Histogram of human connectome, non-zero edge weights\")\n",
    "sns.histplot(A_ptr[A_ptr > 0].flatten(), ax=axs[1], color=\"gray\")\n",
    "axs[1].set_xlabel(\"ptr(Edge weight)\")\n",
    "axs[1].set_title(\"Histogram of human connectome, passed-to-ranks\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        print(\"Scaling edge-weights...\")\n",
    "        A_scaled = pass_to_ranks(X)\n",
    "        return (A_scaled)\n",
    "    \n",
    "feature_scaler = FeatureScaler()\n",
    "A_cleaned_scaled = feature_scaler.transform(A_clean)\n",
    "# Scaling edge-weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ca9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('cleaner', CleanData()),\n",
    "    ('scaler', FeatureScaler()),\n",
    "])\n",
    "\n",
    "A_xfm = num_pipeline.fit_transform(A)\n",
    "# Cleaning data...\n",
    "# Purging 0 nodes...\n",
    "# Scaling edge-weights.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_xfm2 = num_pipeline.fit_transform(As[1])\n",
    "# Cleaning data...\n",
    "# Purging 0 nodes...\n",
    "# Scaling edge-weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed\n",
    "\n",
    "embedding = AdjacencySpectralEmbed(n_components=3, svd_seed=0).fit_transform(A_xfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.plot import pairplot\n",
    "\n",
    "_ = pairplot(embedding, title=\"Spectral Embedding for connectome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a051a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "labels = KMeans(n_clusters=2, random_state=0).fit_predict(embedding)\n",
    "_ = pairplot(embedding, labels=labels, legend_name=\"Predicter Clusters\", \n",
    "                 title=\"KMeans clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.cluster import KMeansCluster\n",
    "\n",
    "labels = KMeansCluster(max_clusters=10, random_state=0).fit_predict(embedding)\n",
    "_ = pairplot(embedding, labels=labels, title=\"KMeans clustering, automatic selection\", \n",
    "                 legend_name=\"Predicted Clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39df1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.cluster import AutoGMMCluster\n",
    "\n",
    "labels = AutoGMMCluster(max_components=10, random_state=0).fit_predict(embedding)\n",
    "_ = pairplot(embedding, labels=labels, title=\"AutoGMM Clustering, automatic selection\", \n",
    "                  legend_name=\"Predicted Clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f703da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import MultipleASE \n",
    "\n",
    "# transform all the networks with pipeline utility\n",
    "As_xfm = [num_pipeline.fit_transform(A) for A in As]\n",
    "# and embed them\n",
    "embedding = MultipleASE(n_components=5, svd_seed=0).fit_transform(As_xfm)\n",
    "_ = pairplot(embedding, title=\"Multiple spectral embedding of all connectomes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef80053",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = AutoGMMCluster(max_components=10, random_state=0).fit_predict(embedding)\n",
    "_ = pairplot(embedding, labels=labels,\n",
    "                title=\"Multiple spectral embedding of all connectomes\", \n",
    "                legend_name=\"Predicted Clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437715b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "coord_dest = os.path.join(FMRI_PATH,  \"coordinates.json\")\n",
    "with open(coord_dest) as coord_f:\n",
    "    coords = []\n",
    "    for roiname, contents in json.load(coord_f)[\"rois\"].items():\n",
    "        try:\n",
    "            if roiname != \"0\":\n",
    "                coord_roi = {\"x\" : contents[\"center\"][0], \"y\" : contents[\"center\"][1], \"z\" : contents[\"center\"][2]}\n",
    "                coords.append(coord_roi)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "coords_df = pd.DataFrame(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d858cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "coords_df[\"Community\"] = labels\n",
    "coords_df['Community'] = coords_df['Community'].astype('category')\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n",
    "axs[0].imshow(mpimg.imread('./Images/lobes.png'))\n",
    "axs[0].set_axis_off()\n",
    "sns.scatterplot(x=\"y\", y=\"z\", data=coords_df, hue=\"Community\", ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd62b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.dice as dice\n",
    "\n",
    "# obtain the Yeo7 parcellation\n",
    "group_dest = os.path.join(\"./datasets/\", \"Yeo-7_space-MNI152NLin6_res-2x2x2.nii.gz\")\n",
    "request.urlretrieve(\"https://github.com/neurodata/neuroparc/\" + \"blob/master/atlases/label/Human/\" +\n",
    "                    \"Yeo-7_space-MNI152NLin6_res-2x2x2.nii.gz?raw=true\", group_dest);\n",
    "# obtain the Shaefer parcellation\n",
    "roi_dest = os.path.join(\"./datasets/\", parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz\")\n",
    "request.urlretrieve(\"https://github.com/neurodata/neuroparc/\" + \"blob/master/atlases/label/Human/\" + \n",
    "                    parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz?raw=true\", roi_dest);\n",
    "\n",
    "# decipher which Schaefer labels fall within Yeo7 regions\n",
    "dicemap, _, _ = dice.dice_roi(\"./datasets/\", \"./datasets\", \n",
    "                              \"Yeo-7_space-MNI152NLin6_res-2x2x2.nii.gz\", \n",
    "                              parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz\",\n",
    "                              verbose=False)\n",
    "actual_cluster = np.argmax(dicemap, axis=0)[1:] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from graphbook_code import cmaps\n",
    "\n",
    "# make confusion matrix\n",
    "cf_matrix = confusion_matrix(actual_cluster, labels)\n",
    "\n",
    "# and plot it\n",
    "ax = sns.heatmap(cf_matrix, cmap=cmaps[\"sequential\"])\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "ax.set_ylabel(\"True Parcel\")\n",
    "ax.set_xlabel(\"Predicted Community\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
