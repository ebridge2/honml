{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "474ecd23",
      "cell_type": "markdown",
      "source": "(ch2:code_repr)=\n# Code Reproducibility",
      "metadata": {}
    },
    {
      "id": "88a93b0b",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import os\nimport urllib\nimport boto3\nfrom botocore import UNSIGNED\nfrom botocore.client import Config\nfrom graspologic.utils import import_edgelist\nimport numpy as np\nimport glob\nfrom tqdm import tqdm\n\n# the AWS bucket the data is stored in\nBUCKET_ROOT = \"open-neurodata\"\nparcellation = \"Schaefer400\"\nFMRI_PREFIX = \"m2g/Functional/BNU1-11-12-20-m2g-func/Connectomes/\" + parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz/\"\nFMRI_PATH = os.path.join(\"datasets\", \"fmri\")  # the output folder\nDS_KEY = \"abs_edgelist\"  # correlation matrices for the networks to exclude\n\ndef fetch_fmri_data(bucket=BUCKET_ROOT, fmri_prefix=FMRI_PREFIX,\n                    output=FMRI_PATH, name=DS_KEY):\n    \"\"\"\n    A function to fetch fMRI connectomes from AWS S3.\n    \"\"\"\n    # check that output directory exists\n    if not os.path.isdir(FMRI_PATH):\n        os.makedirs(FMRI_PATH)\n    # start boto3 session anonymously\n    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n    # obtain the filenames\n    bucket_conts = s3.list_objects(Bucket=bucket, \n                    Prefix=fmri_prefix)[\"Contents\"]\n    for s3_key in tqdm(bucket_conts):\n        # get the filename\n        s3_object = s3_key['Key']\n        # verify that we are grabbing the right file\n        if name not in s3_object:\n            op_fname = os.path.join(FMRI_PATH, str(s3_object.split('/')[-1]))\n            if not os.path.exists(op_fname):\n                s3.download_file(bucket, s3_object, op_fname)\n\ndef read_fmri_data(path=FMRI_PATH):\n    \"\"\"\n    A function which loads the connectomes as adjacency matrices.\n    \"\"\"\n    fnames = glob.glob(os.path.join(path, \"*.csv\"))\n    # sort for consistency\n    fnames.sort()\n    # import edgelists with graspologic\n    # edgelists will be all of the files that end in a csv\n    networks = [import_edgelist(fname) for fname in tqdm(fnames)]\n    return np.stack(networks, axis=0)",
      "outputs": []
    },
    {
      "id": "dd1a7bdc",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "fetch_fmri_data()\nAs = read_fmri_data()",
      "outputs": []
    },
    {
      "id": "ae6ac71e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import heatmap\n\nA = As[0]\nax = heatmap(A, vmin=-1, vmax=1, title=\"Heatmap of Functional Connectome\")",
      "outputs": []
    },
    {
      "id": "68b7c581",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\nax = sns.histplot(A.flatten(), bins=50)\nax.set_xlabel(\"Edge weight\")\nax.set_title(\"Histogram of functional connectome edge-weights\")",
      "outputs": []
    },
    {
      "id": "45a59e09",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def remove_isolates(A):\n    \"\"\"\n    A function which removes isolated nodes from the \n    adjacency matrix A.\n    \"\"\"\n    degree = A.sum(axis=0)  # sum along the rows to obtain the node degree\n    out_degree = A.sum(axis=1)\n    A_purged = A[~(degree == 0),:]\n    A_purged = A_purged[:,~(degree == 0)]\n    print(\"Purging {:d} nodes...\".format((degree == 0).sum()))\n    return A_purged\n    \nA = remove_isolates(A)\n# Purging 0 nodes...",
      "outputs": []
    },
    {
      "id": "a3b6ca3d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import matplotlib.pyplot as plt\nfrom graphbook_code import heatmap\n\nA_abs = np.abs(A)\nfig, axs = plt.subplots(1,3, figsize=(21, 6))\nheatmap(A, ax=axs[0], title=\"Human Connectome, Raw\", vmin=np.min(A), vmax=1)\nheatmap(A_abs, ax=axs[1], title=\"Human Connectome, Absolute\", vmin=np.min(A), vmax=1)\nheatmap(A_abs - A, ax=axs[2], title=\"Difference(Absolute - Raw)\", vmin=0, vmax=1)",
      "outputs": []
    },
    {
      "id": "2aa4e7e9",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from sklearn.base import TransformerMixin, BaseEstimator\n\nclass CleanData(BaseEstimator, TransformerMixin):\n\n    def fit(self, X):\n        return self\n\n    def transform(self, X):\n        print(\"Cleaning data...\")\n        Acleaned = remove_isolates(X)\n        A_abs_cl = np.abs(Acleaned)\n        self.A_ = A_abs_cl\n        return self.A_\n\ndata_cleaner = CleanData()\nA_clean = data_cleaner.transform(A)\n# Cleaning data...\n# Purging 0 nodes...",
      "outputs": []
    },
    {
      "id": "eeb0a536",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.utils import binarize\n\nthreshold = 0.4\nA_bin = binarize(A_clean > threshold)",
      "outputs": []
    },
    {
      "id": "6ca28d27",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.utils import pass_to_ranks\n\nA_ptr = pass_to_ranks(A_clean)",
      "outputs": []
    },
    {
      "id": "f11c6502",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import seaborn as sns\n\nfig, axs = plt.subplots(2, 1, figsize=(10, 10))\nsns.histplot(A_clean[A_clean > 0].flatten(), ax=axs[0], color=\"gray\")\naxs[0].set_xlabel(\"Edge weight\")\naxs[0].set_title(\"Histogram of human connectome, non-zero edge weights\")\nsns.histplot(A_ptr[A_ptr > 0].flatten(), ax=axs[1], color=\"gray\")\naxs[1].set_xlabel(\"ptr(Edge weight)\")\naxs[1].set_title(\"Histogram of human connectome, passed-to-ranks\")\n\nplt.tight_layout()",
      "outputs": []
    },
    {
      "id": "5ed1b2b3",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "class FeatureScaler(BaseEstimator, TransformerMixin):\n    \n    def fit(self, X):\n        return self\n    \n    def transform(self, X):\n        print(\"Scaling edge-weights...\")\n        A_scaled = pass_to_ranks(X)\n        return (A_scaled)\n    \nfeature_scaler = FeatureScaler()\nA_cleaned_scaled = feature_scaler.transform(A_clean)\n# Scaling edge-weights...",
      "outputs": []
    },
    {
      "id": "b721e768",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from sklearn.pipeline import Pipeline\n\nnum_pipeline = Pipeline([\n    ('cleaner', CleanData()),\n    ('scaler', FeatureScaler()),\n])\n\nA_xfm = num_pipeline.fit_transform(A)\n# Cleaning data...\n# Purging 0 nodes...\n# Scaling edge-weights..",
      "outputs": []
    },
    {
      "id": "a4a7e5d5",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "A_xfm2 = num_pipeline.fit_transform(As[1])\n# Cleaning data...\n# Purging 0 nodes...\n# Scaling edge-weights...",
      "outputs": []
    },
    {
      "id": "00a04e1c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import AdjacencySpectralEmbed\n\nembedding = AdjacencySpectralEmbed(n_components=3, svd_seed=0).fit_transform(A_xfm)",
      "outputs": []
    },
    {
      "id": "3a743fe6",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.plot import pairplot\n\n_ = pairplot(embedding, title=\"Spectral Embedding for connectome\")",
      "outputs": []
    },
    {
      "id": "946749f2",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from sklearn.cluster import KMeans\n\nlabels = KMeans(n_clusters=2, random_state=0).fit_predict(embedding)\n_ = pairplot(embedding, labels=labels, legend_name=\"Predicter Clusters\", \n                 title=\"KMeans clustering\")",
      "outputs": []
    },
    {
      "id": "c91a0d23",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.cluster import KMeansCluster\n\nlabels = KMeansCluster(max_clusters=10, random_state=0).fit_predict(embedding)\n_ = pairplot(embedding, labels=labels, title=\"KMeans clustering, automatic selection\", \n                 legend_name=\"Predicted Clusters\")",
      "outputs": []
    },
    {
      "id": "506986cf",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.cluster import AutoGMMCluster\n\nlabels = AutoGMMCluster(max_components=10, random_state=0).fit_predict(embedding)\n_ = pairplot(embedding, labels=labels, title=\"AutoGMM Clustering, automatic selection\", \n                  legend_name=\"Predicted Clusters\")",
      "outputs": []
    },
    {
      "id": "e874e966",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import MultipleASE \n\n# transform all the networks with pipeline utility\nAs_xfm = [num_pipeline.fit_transform(A) for A in As]\n# and embed them\nembedding = MultipleASE(n_components=5, svd_seed=0).fit_transform(As_xfm)\n_ = pairplot(embedding, title=\"Multiple spectral embedding of all connectomes\")",
      "outputs": []
    },
    {
      "id": "9da82ec8",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "labels = AutoGMMCluster(max_components=10, random_state=0).fit_predict(embedding)\n_ = pairplot(embedding, labels=labels,\n                title=\"Multiple spectral embedding of all connectomes\", \n                legend_name=\"Predicted Clusters\")",
      "outputs": []
    },
    {
      "id": "b0f168ac",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from urllib import request\nimport json\nimport pandas as pd\nfrom pathlib import Path\n\ncoord_dest = os.path.join(FMRI_PATH,  \"coordinates.json\")\nwith open(coord_dest) as coord_f:\n    coords = []\n    for roiname, contents in json.load(coord_f)[\"rois\"].items():\n        try:\n            if roiname != \"0\":\n                coord_roi = {\"x\" : contents[\"center\"][0], \"y\" : contents[\"center\"][1], \"z\" : contents[\"center\"][2]}\n                coords.append(coord_roi)\n        except:\n            continue\n            \ncoords_df = pd.DataFrame(coords)",
      "outputs": []
    },
    {
      "id": "ced9bbff",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import matplotlib.image as mpimg\n\ncoords_df[\"Community\"] = labels\ncoords_df['Community'] = coords_df['Community'].astype('category')\nfig, axs = plt.subplots(1, 2, figsize=(18, 6))\naxs[0].imshow(mpimg.imread('./Images/lobes.png'))\naxs[0].set_axis_off()\nsns.scatterplot(x=\"y\", y=\"z\", data=coords_df, hue=\"Community\", ax=axs[1])",
      "outputs": []
    },
    {
      "id": "79304f03",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import datasets.dice as dice\n\n# obtain the Yeo7 parcellation\ngroup_dest = os.path.join(\"./datasets/\", \"Yeo-7_space-MNI152NLin6_res-2x2x2.nii.gz\")\nrequest.urlretrieve(\"https://github.com/neurodata/neuroparc/\" + \"blob/master/atlases/label/Human/\" +\n                    \"Yeo-7_space-MNI152NLin6_res-2x2x2.nii.gz?raw=true\", group_dest);\n# obtain the Shaefer parcellation\nroi_dest = os.path.join(\"./datasets/\", parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz\")\nrequest.urlretrieve(\"https://github.com/neurodata/neuroparc/\" + \"blob/master/atlases/label/Human/\" + \n                    parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz?raw=true\", roi_dest);\n\n# decipher which Schaefer labels fall within Yeo7 regions\ndicemap, _, _ = dice.dice_roi(\"./datasets/\", \"./datasets\", \n                              \"Yeo-7_space-MNI152NLin6_res-2x2x2.nii.gz\", \n                              parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz\",\n                              verbose=False)\nactual_cluster = np.argmax(dicemap, axis=0)[1:] - 1",
      "outputs": []
    },
    {
      "id": "c3472dd2",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import contextlib\nfrom sklearn.metrics import confusion_matrix\nfrom graphbook_code import cmaps\n\n# make confusion matrix\ncf_matrix = confusion_matrix(actual_cluster, labels)\n\n# and plot it\nax = sns.heatmap(cf_matrix, cmap=cmaps[\"sequential\"])\nax.set_title(\"Confusion matrix\")\nax.set_ylabel(\"True Parcel\")\nax.set_xlabel(\"Predicted Community\")",
      "outputs": []
    }
  ]
}