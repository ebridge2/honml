{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446bc7bb-b427-442b-ba98-338fc3f30b67",
   "metadata": {},
   "source": [
    "# Code Reproducibility: Chapter 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2588300-8d58-44b5-b1cf-2b58cb8d08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.simulations import sbm\n",
    "import numpy as np\n",
    "from graphbook_code import dcsbm, generate_dcsbm_pmtx, \\\n",
    "                           generate_sbm_pmtx\n",
    "\n",
    "\n",
    "n = 100  # the number of nodes\n",
    "# human brains have homophilic block structure\n",
    "Bhum = np.array([[0.2, 0.02], [0.02, 0.2]])\n",
    "# alien brains add degree-correction\n",
    "theta_alien = np.tile(np.linspace(1.5, 0.5, n // 2), 2)\n",
    "\n",
    "# generate human and alien brain network\n",
    "np.random.seed(0)\n",
    "A_human, z = sbm([n // 2, n // 2], Bhum, return_labels=True)\n",
    "A_alien = dcsbm(z, theta_alien, Bhum)\n",
    "\n",
    "Phum = generate_sbm_pmtx(z, Bhum)\n",
    "Palien = generate_dcsbm_pmtx(z, theta_alien, Bhum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import orthogonal_procrustes\n",
    "from graspologic.embed import AdjacencySpectralEmbed as ase\n",
    "\n",
    "d = 2\n",
    "# estimate latent positions for alien and human networks\n",
    "Xhat_human = ase(n_components=d).fit_transform(A_human)\n",
    "Xhat_alien = ase(n_components=d).fit_transform(A_alien)\n",
    "# estimate best possible orthogonal transform of Xhat_alien to Xhat_human by \n",
    "# solving orthogonal procrustes problem\n",
    "W = orthogonal_procrustes(Xhat_alien, Xhat_human)[0]\n",
    "observed_norm = np.linalg.norm(Xhat_human - Xhat_alien @ W, ord=\"fro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f423e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.simulations import rdpg\n",
    "\n",
    "def generate_synthetic_networks(X):\n",
    "    \"\"\"\n",
    "    A function which generates two synthetic networks with\n",
    "    same latent position matrix X.\n",
    "    \"\"\"\n",
    "    A1 = rdpg(X, directed=False, loops=False)\n",
    "    A2 = rdpg(X, directed=False, loops=False)\n",
    "    return A1, A2\n",
    "\n",
    "Ap, App = generate_synthetic_networks(Xhat_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc766348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latent(A, d):\n",
    "    \"\"\"\n",
    "    A function which returns the latent position estimate\n",
    "    for an adjacency matrix A.\n",
    "    \"\"\"\n",
    "    return ase(n_components=d).fit_transform(A)\n",
    "\n",
    "Xhat_p = compute_latent(Ap, d)\n",
    "Xhat_pp = compute_latent(App, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb78cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_norm_orth_proc(A, B):\n",
    "    \"\"\"\n",
    "    A function which finds the best orthogonal transform \n",
    "    of B onto A, and then computes and returns the norm.\n",
    "    \"\"\"\n",
    "    R = orthogonal_procrustes(B, A)[0]\n",
    "    return np.linalg.norm(A - B @ R)\n",
    "\n",
    "norm_null = compute_norm_orth_proc(Xhat_p, Xhat_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad00b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametric_resample(A1, A2, d, nreps=100):\n",
    "    \"\"\"\n",
    "    A function to generate samples of the null distribution under H0\n",
    "    using parametric resampling.\n",
    "    \"\"\"\n",
    "    null_norms = np.zeros(nreps)\n",
    "    Xhat1 = compute_latent(A1, d)\n",
    "    for i in range(0, nreps):\n",
    "        Ap, App = generate_synthetic_networks(Xhat1)\n",
    "        Xhat_p = compute_latent(Ap, d)\n",
    "        Xhat_pp = compute_latent(App, d)\n",
    "        null_norms[i] = compute_norm_orth_proc(Xhat_p, Xhat_pp)\n",
    "    return null_norms\n",
    "\n",
    "nreps = 100\n",
    "null_norms = parametric_resample(A_alien, A_human, 2, nreps=nreps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3c0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = ((null_norms >= observed_norm).sum() + 1)/(nreps + 1)\n",
    "print(f\"estimate of p-value: {pval:.5f}\")\n",
    "# estimate of p-value: 0.00990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.inference import latent_position_test\n",
    "\n",
    "nreps = 100 # the number of null replicates\n",
    "lpt = latent_position_test(A_human, A_alien, n_bootstraps = nreps, n_components=d, workers=-1)\n",
    "print(\"estimate of p-value: {:.5f}\".format(lpt[1]))\n",
    "# estimate of p-value: 0.00990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a new human brain network with same block matrix\n",
    "A_human2 = sbm([n // 2, n // 2], Bhum)\n",
    "\n",
    "lpt_hum2hum = latent_position_test(A_human, A_human2, n_bootstraps=nreps, n_components=d, workers=-1)\n",
    "print(\"estimate of p-value: {:.5f}\".format(lpt_hum2hum[1]))\n",
    "# estimate of p-value: 0.386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452dcd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncoins = 300  # the number of coins in each container\n",
    "\n",
    "# the probabilities from container 1 landing on heads\n",
    "# with a much larger variance\n",
    "pi1 = np.random.beta(a=4, b=4, size=ncoins)\n",
    "\n",
    "# the probabilities of container 2 landing on heads,\n",
    "# with a much smaller variance\n",
    "pi2 = np.random.beta(a=15, b=15, size=ncoins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.inference import latent_distribution_test\n",
    "\n",
    "nreps = 100\n",
    "approach = 'mgc'  # the strategy for the latent distribution test\n",
    "ldt_dcorr = latent_distribution_test(A_human, A_alien, test=approach, metric=\"euclidean\", n_bootstraps=nreps, workers=-1)\n",
    "print(\"estimate of p-value: {:.5f}\".format(ldt_dcorr.pvalue))\n",
    "# estimate of p-value: 0.00990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da385d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"estimate of p-value: {:.4f}\".format(ldt_dcorr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "ns = [45, 30, 25]  # number of exits\n",
    "\n",
    "states = [\"NY\", \"NJ\", \"PA\"]\n",
    "# z is a column vector indicating which state each exit is in\n",
    "z = np.repeat(states, ns)\n",
    "\n",
    "Bnight = np.array([[.3, .2, .05], [.2, .3, .05], [.05, .05, .3]])\n",
    "Bday = Bnight*2  # day time block matrix is generally 50% more than night\n",
    "\n",
    "# people tend to commute from New Jersey to New York during the day\n",
    "# at anomalously high rates\n",
    "Bday[0, 1] = .5; Bday[1,0] = .5\n",
    "\n",
    "np.random.seed(0)\n",
    "Anight = sbm(ns, Bnight)\n",
    "Aday = sbm(ns, Bday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dfb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "\n",
    "K = 3\n",
    "Pvals = np.empty((K, K))\n",
    "# fill matrix with NaNs\n",
    "Pvals[:] = np.nan\n",
    "\n",
    "# get the indices of the upper triangle of Aday\n",
    "upper_tri_idx = np.triu_indices(Aday.shape[0], k=1)\n",
    "# create a boolean array that is nxn\n",
    "upper_tri_mask = np.zeros(Aday.shape, dtype=bool)\n",
    "# set indices which correspond to the upper triangle to True\n",
    "upper_tri_mask[upper_tri_idx] = True\n",
    "\n",
    "for k in range(0, K):\n",
    "    for l in range(k, K):\n",
    "        comm_mask = np.outer(z == states[k], z == states[l])\n",
    "        table = [[Aday[comm_mask & upper_tri_mask].sum(),\n",
    "                 (Aday[comm_mask & upper_tri_mask] == 0).sum()],\n",
    "                 [Anight[comm_mask & upper_tri_mask].sum(),\n",
    "                 (Anight[comm_mask & upper_tri_mask] == 0).sum()]]\n",
    "        Pvals[k,l] = fisher_exact(table)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd57ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import er_np\n",
    "import seaborn as sns\n",
    "from scipy.stats import binomtest\n",
    "\n",
    "ncoins = 5000 # the number of coins\n",
    "p = 0.5  # the true probability\n",
    "n = 500  # the number of flips\n",
    "\n",
    "# the number of heads from each experiment\n",
    "experiments = np.random.binomial(n, p, size=ncoins)\n",
    "\n",
    "# perform binomial test to see if the number of heads we obtain supports that the\n",
    "# true probabiily is 0.5\n",
    "pvals = [binomtest(nheads_i, n, p=p).pvalue for nheads_i in experiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "alpha = 0.05  # the desired alpha of the test\n",
    "_, adj_pvals, _, _ = multipletests(pvals, alpha=alpha, method=\"holm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18299e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import symmetrize\n",
    "\n",
    "Pvals_adj = multipletests(Pvals.flatten(), method=\"holm\")[1].reshape(K, K)\n",
    "Pvals_adj = symmetrize(Pvals_adj, method=\"triu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02864a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_dif = Pvals_adj.min()\n",
    "print(f\"p-value of block matrix difference: {pval_dif:.4f}\")\n",
    "# p-value of block matrix difference: 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.inference import group_connection_test\n",
    "\n",
    "stat, pval_diff_rescale, misc = group_connection_test(Aday, Anight,\n",
    "    labels1=z, labels2=z, density_adjustment=True)\n",
    "Pval_adj_rescaled = np.array(misc[\"corrected_pvalues\"])\n",
    "print(f\"p-value of block matrix difference, after rescaling: {pval_diff_rescale:.4f}\")\n",
    "# p-value of block matrix difference, after rescaling: 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3],\n",
    "    [4,4,4,4]\n",
    "])\n",
    "\n",
    "P = np.array([\n",
    "    [0,1,0,0],\n",
    "    [1,0,0,0],\n",
    "    [0,0,1,0],\n",
    "    [0,0,0,1]\n",
    "])\n",
    "\n",
    "row_reordering = P.T @ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4]\n",
    "])\n",
    "\n",
    "column_reordering = B @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca4423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([\n",
    "    [1,1,1,1],\n",
    "    [1,0,0,0],\n",
    "    [1,0,0,0],\n",
    "    [1,0,0,0]\n",
    "])\n",
    "\n",
    "row_reordering_C = P.T @ C\n",
    "row_column_reordering = row_reordering_C @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f43e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "insta = np.array([\n",
    "    [0,1,1,0],\n",
    "    [1,0,0,1],\n",
    "    [1,0,0,1],\n",
    "    [0,1,1,0]\n",
    "])\n",
    "\n",
    "facebook_permuted = np.array([\n",
    "    [0,1,0,1],\n",
    "    [1,0,1,0],\n",
    "    [0,1,0,1],\n",
    "    [1,0,1,0]\n",
    "])\n",
    "\n",
    "# the permutation to unshuffle the facebook\n",
    "# permuted adjacency matrix\n",
    "Pu = np.array([\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,0,1],\n",
    "    [0,0,1,0]\n",
    "])\n",
    "\n",
    "fb_unpermuted = Pu.T @ facebook_permuted @ Pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f41986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_permutation(n, random_seed=0):\n",
    "    \"\"\"\n",
    "    A function that generates a random permutation matric $P$ for n elements.\n",
    "    \n",
    "    1. Generate indices from 0 to n-1\n",
    "    2. shuffle those indices\n",
    "    3. Place 1s in the matrix P at the positions defined by the shuffled indices.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=random_seed)\n",
    "    starting_indices = np.arange(n)\n",
    "    destination_indices = rng.permutation(n)\n",
    "    P = np.zeros(shape=(n,n))\n",
    "    P[destination_indices, starting_indices] = 1\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3666d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.simulations import er_np\n",
    "\n",
    "n = 12\n",
    "p = 0.5\n",
    "\n",
    "np.random.seed(0)\n",
    "A = er_np(n=n, p=p)\n",
    "# make a random permutation matrix\n",
    "P = make_random_permutation(n)\n",
    "B = P.T @ A @ P\n",
    "disagreements = np.linalg.norm(A - B)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcecbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.match import graph_match\n",
    "\n",
    "gmp = graph_match(A,B, n_init=10, rng=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14cb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unshuffler(destination_indices):\n",
    "    \"\"\"\n",
    "    A function which creates a permutation matrix P from a given permutation of the nodes.\n",
    "    \"\"\"\n",
    "    n = len(destination_indices)\n",
    "    Pu = np.zeros((n, n))\n",
    "    starting_indices = np.arange(n)\n",
    "    Pu[destination_indices, starting_indices] = 1\n",
    "    return Pu\n",
    "\n",
    "Pu = make_unshuffler(gmp.indices_B)\n",
    "B_unshuffled = Pu.T @ B @ Pu\n",
    "disagreements = np.linalg.norm(A - B_unshuffled)**2\n",
    "print(f\"Disagreements: {int(disagreements):d}\")\n",
    "# Disagreements: 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ef9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_ratio(P, Pu):\n",
    "    n = P.shape[0]  # the number of nodes\n",
    "    return (np.diag(Pu @ P) == 1).sum()/n\n",
    "\n",
    "print(f\"match ratio: {match_ratio(P, Pu):.3f}\")\n",
    "# match ratio: 1.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16038c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.simulations import sbm_corr\n",
    "\n",
    "n_per_block = 75\n",
    "n_blocks = 3\n",
    "block_members = np.repeat(n_per_block, repeats=n_blocks)\n",
    "n_nodes = block_members.sum()\n",
    "rho = 0.5\n",
    "block_probs = np.array(\n",
    "    [[0.7, 0.1, 0.4], \n",
    "     [0.1, 0.3, 0.1], \n",
    "     [0.4, 0.1, 0.7]]\n",
    ")\n",
    "\n",
    "np.random.seed(0)\n",
    "A1, A2 = sbm_corr(block_members, block_probs, rho)\n",
    "disagreements = np.linalg.norm(A1 - A2)**2\n",
    "print(f\"Disagreements (Unshuffled): {int(disagreements):d}\")\n",
    "# Disagreements (Unshuffled): 8041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = make_random_permutation(n_nodes)\n",
    "A2_shuffle = P.T @ A2 @ P\n",
    "disagreements_shuffled = np.linalg.norm(A1 - A2_shuffle)**2\n",
    "print(f\"Disagreements (Shuffled): {int(disagreements_shuffled):d}\")\n",
    "# Disagreements (Shuffled): 22201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with A and shuffled B\n",
    "gm = graph_match(A1, A2_shuffle, rng=0)\n",
    "\n",
    "# obtain unshuffled version of the shuffled B\n",
    "P_unshuffle_noseed = make_unshuffler(gm.indices_B)\n",
    "A2_unshuffle_noseed = P_unshuffle_noseed.T @ A2_shuffle @ P_unshuffle_noseed\n",
    "\n",
    "# compute the match ratio\n",
    "match_ratio_noseed = match_ratio(P, P_unshuffle_noseed)\n",
    "print(f\"Match Ratio, no seeds: {match_ratio_noseed:.3f}\")\n",
    "# Match Ratio, no seeds: 0.004\n",
    "\n",
    "disagreements_noseed = np.linalg.norm(A1 - A2_unshuffle_noseed)**2\n",
    "print(f\"Disagreements, no seeds: {int(disagreements_noseed):d}\")\n",
    "# Disagreements, no seeds: 12810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1958e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seeds(P, n_seeds, random_seed=0):\n",
    "    \"\"\"\n",
    "    A function to generate n_seeds seeds for a pair of matrices A1 and P^TA2P\n",
    "    which are initially matched, but P has been applied to permute the nodes\n",
    "    of A2.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed=random_seed)\n",
    "    n = P.shape[0]\n",
    "    # obtain n_seeds random seeds from 1:n\n",
    "    seeds = rng.choice(n, size=n_seeds, replace=False)\n",
    "    # use the permutation matrix to find where each seed was permuted to\n",
    "    seeds_permuted = [np.where(P[i, :] == 1)[0] for i in seeds]\n",
    "    return (seeds, seeds_permuted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nseeds = 10  # the number of seeds to use\n",
    "# select ten nodes at random from A which will serve as seeds\n",
    "\n",
    "# obtain seeds for nodes of A1 with nodes of A2 after shuffling\n",
    "seedsA1, seedsA2_shuffled = gen_seeds(P, nseeds)\n",
    "\n",
    "# run SGM with A1 and shuffled A2, but provide the seed nodes from A as ref_seeds\n",
    "# and the corresponding position of these seed nodes after shuffling as permuted_seeds\n",
    "sgm = graph_match(A1, A2_shuffle, partial_match=(seedsA1, seedsA2_shuffled), rng=0)\n",
    "P_unshuffle_seeds = make_unshuffler(sgm.indices_B)\n",
    "A2_unshuffle_seeds = P_unshuffle_seeds.T @ A2_shuffle @ P_unshuffle_seeds\n",
    "\n",
    "match_ratio_seeds = match_ratio(P, P_unshuffle_seeds)\n",
    "print(f\"Match Ratio, seeds: {match_ratio_seeds:.3f}\")\n",
    "# Match Ratio with seeds: 1.000\n",
    "\n",
    "disagreements_seeds = np.linalg.norm(A1 - A2_unshuffle_seeds)**2\n",
    "print(f\"Disagreements, seeds: {int(disagreements_seeds):d}\")\n",
    "# Disagreements, seeds: 8041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775a947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import remove_vertices\n",
    "\n",
    "nremove = 25\n",
    "\n",
    "# nodes to remove from A2\n",
    "n_nodes_A2_N = n_nodes - nremove*n_blocks\n",
    "base_range = np.arange(n_per_block - nremove, n_per_block)\n",
    "block_offsets = np.array([0, 75, 150])\n",
    "\n",
    "# repeat a base range for each block and add block offsets\n",
    "nodes_to_remove = np.repeat(base_range, len(block_offsets)) \n",
    "nodes_to_remove += np.tile(block_offsets, nremove)\n",
    "N = np.setdiff1d(np.arange(n_nodes), nodes_to_remove)\n",
    "\n",
    "# use the remove_vertices function to compute\n",
    "# the subnetwork induced by the nodes nodes_to_retain\n",
    "A2_N = remove_vertices(A2, nodes_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a01af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1_N = remove_vertices(A1, nodes_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dccd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2_N_padded = np.pad(\n",
    "    A2_N, \n",
    "    pad_width=[(0,nremove*n_blocks), (0, nremove*n_blocks)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nseeds_padded = 10\n",
    "\n",
    "np.random.seed(0)\n",
    "# obtain which nodes of A2 will be the seeds to use, from the retained nodes in the network\n",
    "seeds_A2_N = np.random.choice(n_nodes_A2_N, size=nseeds_padded, replace=False)\n",
    "\n",
    "# obtain the nodes in A1\n",
    "seeds_A1 = N[seeds_A2_N]\n",
    "\n",
    "# run SGM with A1 and the padded network A2\n",
    "# since we didn't shuffle A(2),r, we do not need\n",
    "# to worry about permuting the seeds\n",
    "sgm_naive = graph_match(A1, A2_N, partial_match=(seeds_A1, seeds_A2_N),\n",
    "                        padding=\"naive\", rng=0, n_init=5)\n",
    "\n",
    "# unshuffle A2_N using indices_B\n",
    "P_unshuffle = make_unshuffler(sgm_naive.indices_B)\n",
    "A2_N_unshuffle_seeds_naive = P_unshuffle.T @ A2_N @ P_unshuffle\n",
    "\n",
    "A2_naive_full = np.zeros(A1.shape)\n",
    "A2_naive_full[np.ix_(sgm_naive.indices_A, sgm_naive.indices_A)] = A2_N_unshuffle_seeds_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2_naive_full = np.zeros(A1.shape)\n",
    "A2_naive_full[np.ix_(sgm_naive.indices_A, sgm_naive.indices_A)] = A2_N_unshuffle_seeds_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1_induced = remove_vertices(A1, nodes_to_remove)\n",
    "disagreements_naive = np.linalg.norm(A1_induced - A2_N_unshuffle_seeds_naive)**2\n",
    "print(f\"Disagreements, naive padding: {int(disagreements_naive):d}\")\n",
    "# Disagreements, adopted padding: 9285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1tilde = 2 * A1 - np.ones(A1.shape[0])\n",
    "A2tilde_N = 2*A2_N - np.ones(A2_N.shape[0])\n",
    "A2tilde_N_padded = np.pad(A2tilde_N, [(0,nremove*n_blocks), (0, nremove*n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run SGM with A1 and A2[N] with nodes removed\n",
    "sgm_adopted = graph_match(A1, A2_N, partial_match=(seeds_A1, seeds_A2_N), padding=\"adopted\", rng=0, n_init=5)\n",
    "\n",
    "# unshuffle A2[N] using the permutation identified\n",
    "P_unshuffle_ad = make_unshuffler(sgm_adopted.indices_B)\n",
    "A2_N_unshuffle_seeds_adopted = P_unshuffle_ad.T @ A2_N @ P_unshuffle_ad\n",
    "\n",
    "A2_adopted_full = np.zeros(A1.shape)\n",
    "A2_adopted_full[np.ix_(sgm_adopted.indices_A, sgm_adopted.indices_A)] = A2_N_unshuffle_seeds_adopted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c2f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ratio_adopted = match_ratio(np.eye(A1_induced.shape[0]), P_unshuffle_ad)\n",
    "print(f\"Match Ratio, adopted padding: {match_ratio_adopted:.3f}\")\n",
    "# Match Ratio, adopted padding: 0.887\n",
    "\n",
    "disagreements_adopted = np.linalg.norm(A1_induced - A2_N_unshuffle_seeds_adopted)**2\n",
    "print(f\"Disagreements, adopted padding: {int(disagreements_adopted):d}\")\n",
    "# Disagreements, adopted padding: 4186"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
