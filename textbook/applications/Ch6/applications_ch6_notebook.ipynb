{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd3e071-5f37-46e9-8495-bad495db8c07",
   "metadata": {},
   "source": [
    "(ch6:code_repr)=\n",
    "# Code Reproducibility: Ch6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1435a349-be67-4043-b020-6b2963698c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graphbook_code import dcsbm\n",
    "\n",
    "nk = 100  # 100 nodes per community\n",
    "K = 3  # the number of communities\n",
    "n = nk * K  # total number of nodes\n",
    "\n",
    "zs = np.repeat(np.arange(K)+1, repeats=nk)\n",
    "# block matrix and degree-correction factor\n",
    "B = np.array([[0.7, 0.2, 0.1], [0.2, 0.5, 0.1], [0.1, 0.1, 0.4]])\n",
    "theta = np.tile(np.linspace(start=0, stop=1, num=nk), reps=K)\n",
    "# generate network sample\n",
    "np.random.seed(0)\n",
    "A = dcsbm(zs, theta, B)\n",
    "\n",
    "# permute the nodes randomly\n",
    "vtx_perm = np.random.choice(n, size=n, replace=False)\n",
    "Aperm = A[vtx_perm, :][:,vtx_perm]\n",
    "zperm = zs[vtx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a456552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from graspologic.embed import AdjacencySpectralEmbed as ase\n",
    "\n",
    "Xhat = ase(n_components=3, svd_seed=0).fit_transform(Aperm)\n",
    "D = sp.spatial.distance_matrix(Xhat, Xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6475471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "labels_kmeans = KMeans(n_clusters = 3, random_state=0).fit_predict(Xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e4ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# compute the confusion matrix between the true labels z\n",
    "# and the predicted labels labels_kmeans\n",
    "cf_matrix = confusion_matrix(zperm, labels_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bcaef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "ari_kmeans = adjusted_rand_score(zperm, labels_kmeans)\n",
    "print(ari_kmeans)\n",
    "# 0.490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import remap_labels\n",
    "\n",
    "labels_kmeans_remap = remap_labels(zperm, labels_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a67df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute which assigned labels from labels_kmeans_remap differ from the true labels z\n",
    "error = zperm - labels_kmeans_remap\n",
    "# if the difference between the community labels is non-zero, an error has occurred\n",
    "error = error != 0\n",
    "error_rate = np.mean(error)  # error rate is the frequency of making an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xhat = ase(svd_state=0).fit_transform(Aperm)\n",
    "print(\"Estimated number of dimensions: {:d}\".format(Xhat.shape[1]))\n",
    "# Estimated number of dimensions: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.cluster import KMeansCluster\n",
    "\n",
    "km_clust = KMeansCluster(max_clusters = 10, random_state=0)\n",
    "labels_kmclust = km_clust.fit_predict(Xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b4951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "nclusters = range(2, 11)  # graspologic nclusters goes from 2 to max_clusters\n",
    "silhouette = km_clust.silhouette_ # obtain the respective silhouettes\n",
    "\n",
    "# place into pandas dataframe\n",
    "ss_df = df({\"Number of Communities\": nclusters, \"Silhouette Score\": silhouette})\n",
    "sns.lineplot(data=ss_df, x=\"Number of Communities\", y=\"Silhouette Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sample_edges\n",
    "from graphbook_code import generate_sbm_pmtx\n",
    "    \n",
    "def academic_pmtx(K, nk=10, return_zs=False):\n",
    "    \"\"\"\n",
    "    Produce probability matrix for academic example.\n",
    "    \"\"\"\n",
    "    n = K*nk\n",
    "    # get the community assignments\n",
    "    zs = np.repeat(np.arange(K)+1, repeats=nk)\n",
    "    # randomly generate proteges and lab leaders\n",
    "    unif_choices = np.random.uniform(size=n)\n",
    "    thetas = np.zeros(n)\n",
    "    # 90% are proteges\n",
    "    thetas[unif_choices > .1] = np.random.beta(1, 5, size=(unif_choices > .1).sum())\n",
    "    # 10% are lab leaders\n",
    "    thetas[unif_choices <= .1] = np.random.beta(2, 1, size=(unif_choices <= .1).sum())\n",
    "    # define block matrix\n",
    "    B = np.full(shape=(K,K), fill_value=0.01)\n",
    "    np.fill_diagonal(B, 1)\n",
    "    # generate probability matrix for SBM\n",
    "    Pp = generate_sbm_pmtx(zs, B)\n",
    "    Theta = np.diag(thetas)\n",
    "    # adjust probability matrix for SBM by degree-corrections\n",
    "    P = Theta @ Pp @ Theta.transpose()\n",
    "    if return_zs:\n",
    "        return P, zs\n",
    "    return P\n",
    "\n",
    "def academic_example(K, nk=10, return_zs=False):\n",
    "    P = academic_pmtx(K, nk=nk, return_zs=return_zs)\n",
    "    if return_zs:\n",
    "        return (sample_edges(P[0]), P[1])\n",
    "    else:\n",
    "        return sample_edges(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm  # optional\n",
    "\n",
    "results = []\n",
    "nrep = 50\n",
    "for K in tqdm(np.linspace(start=2, stop=128, num=10, dtype=int)):\n",
    "    for j in range(nrep):\n",
    "        P = academic_pmtx(K)\n",
    "        n = P.shape[0]\n",
    "        results.append({\"Count\": np.triu(P, k=1).sum(), \"Edges\": \"Expected\", \n",
    "                        \"#Nodes\": n, \"Index\": j})\n",
    "        results.append({\"Count\": n*(n - 1)/2000, \"Edges\": \"Potential/1000\",\n",
    "                        \"#Nodes\": n, \"Index\": j})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df_mean=df.groupby([\"Edges\", \"#Nodes\"])[[\"Count\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=df, x=\"#Nodes\", y=\"Count\", hue=\"Edges\")\n",
    "ax.set(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea9df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = pd.pivot(df_mean.reset_index(), index=\"#Nodes\", columns=\"Edges\", values=\"Count\")\n",
    "# remember normalizing constant of 100 for potential edges\n",
    "df_wide[\"Density\"] = df_wide[\"Expected\"]/(1000*df_wide[\"Potential/1000\"])\n",
    "df_wide = df_wide.reset_index()\n",
    "# plot it\n",
    "sns.lineplot(data=df_wide, x=\"#Nodes\", y=\"Density\", color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356cbe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide[\"Degree\"] = df_wide[\"Density\"]*(df_wide[\"#Nodes\"] - 1)\n",
    "sns.lineplot(data=df_wide, x=\"#Nodes\", y=\"Degree\", color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "K = 10; nk = 100\n",
    "P, zs = academic_example(K, nk=nk, return_zs=True)\n",
    "A = sample_edges(P)\n",
    "\n",
    "print(f\"# Non-zero entries: {A.sum().astype(int)}\")  \n",
    "# Non-zero entries: 5308\n",
    "\n",
    "print(f\"# Number of entries: {A.size}\")  \n",
    "# Number of entries: 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size in KB: {A.nbytes/1000:.3f} KB\")\n",
    "# Size in KB: 8000.000 KB\n",
    "\n",
    "B = A.astype(np.uint8)\n",
    "print(f\"Size in KB: {B.nbytes/1000:.3f} KB\")\n",
    "# Size in KB: 1000.000 KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "Btriu = sparse.triu(B)\n",
    "print(f\"Size in KB: {Btriu.data.size/1000:.3f}\")\n",
    "# Size in KB: 2.654 KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb82701",
   "metadata": {},
   "outputs": [],
   "source": [
    "Btriu\n",
    "# <1000x1000 sparse matrix of type '<class 'numpy.uint8'>'\n",
    "#     with 2654 stored elements in COOrdinate format>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05501c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import symmetrize\n",
    "\n",
    "# cast the sparse matrix back to a dense matrix,\n",
    "# and then triu symmetrize with graspologic\n",
    "A_new = symmetrize(Btriu.todense(), method=\"triu\")\n",
    "np.array_equal(A_new, A)  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4129d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy as sp\n",
    "\n",
    "# a naive full svd on the dense matrix\n",
    "timestart = time.time()\n",
    "U, S, Vh = sp.linalg.svd(A)\n",
    "Xhat = U[:, 0:10] @ np.diag(np.sqrt(S[0:10]))\n",
    "timeend = time.time()\n",
    "print(f\"Naive approach: {timeend - timestart:3f} seconds\")\n",
    "# we get about 0.55 seconds\n",
    "\n",
    "# a sparse svd on the sparse matrix\n",
    "Acoo = sparse.coo_array(A)\n",
    "timestart = time.time()\n",
    "U, S, Vh = sp.sparse.linalg.svds(Acoo, k=10)\n",
    "Xhat = U @ np.diag(np.sqrt(S))\n",
    "timeend = time.time()\n",
    "print(f\"Sparse approach: {timeend-timestart:3f} seconds\")\n",
    "# we get about .01 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf753d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = A.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import to_laplacian\n",
    "from graspologic.plot import pairplot\n",
    "\n",
    "# use sparse svd, so that we don't need to compute\n",
    "# 1000 singular vectors and can just calculate the top 10\n",
    "U, S, Vh = sp.sparse.linalg.svds(to_laplacian(A), k=10, random_state=0)\n",
    "# plot the first 4\n",
    "pairplot(U[:,0:4], labels=zs, title=\"Eigenspokes in the Laplacian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vh = sp.sparse.linalg.svds(A, k=10, random_state=0)\n",
    "# plot the first 4\n",
    "fig = pairplot(U[:,0:4], labels=zs, title=\"Eigenspokes in the adjacency matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Expected edges: {:.2f}\".format(np.triu(P).sum()))\n",
    "# Expected edges: 2654.00\n",
    "print(\"# True edges: {:d}\".format(np.triu(A).sum().astype(int)))\n",
    "# True edges: 2654\n",
    "print(\"# Potential edges: {:d}\".format(int(K*nk*(K*nk - 1)/2)))\n",
    "# Potential edges: 499500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graphbook_code import siem\n",
    "\n",
    "n = 100\n",
    "Z = np.ones((n, n))\n",
    "\n",
    "# Fill the upper and lower 50th diagonals with 2\n",
    "# and the main diagonal with 0\n",
    "np.fill_diagonal(Z[:, 50:], 2)\n",
    "np.fill_diagonal(Z[50:, :], 2)\n",
    "np.fill_diagonal(Z, 0)\n",
    "\n",
    "p = [0.4, 0.6]\n",
    "np.random.seed(0)\n",
    "A = siem(n, p, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_pvec = {k: A[Z == k].mean() for k in [1, 2]}\n",
    "print(est_pvec)\n",
    "# {1: 0.3955102040816327, 2: 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad1d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "import numpy as np\n",
    "\n",
    "# assemble the contingency table indicated\n",
    "table = np.array([[3, 7], [7, 3]])\n",
    "_, pvalue = fisher_exact(table)\n",
    "print(f\"p-value: {pvalue:.3f}\")\n",
    "# p-value: 0.179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute an upper-triangular mask to only look at the\n",
    "# upper triangle since the network is simple (undirected and loopless)\n",
    "upper_tri_mask = np.triu(np.ones(A.shape), k=1).astype(bool)\n",
    "column_clust1 = [\n",
    "    A[(Z == 1) & upper_tri_mask].sum(),\n",
    "    (A[(Z == 1) & upper_tri_mask] == 0).sum(),\n",
    "]\n",
    "column_clust2 = [\n",
    "    A[(Z == 2) & upper_tri_mask].sum(),\n",
    "    (A[(Z == 2) & upper_tri_mask] == 0).sum(),\n",
    "]\n",
    "cont_tabl = np.vstack((column_clust1, column_clust2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ff981",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pvalue = fisher_exact(cont_tabl)\n",
    "print(f\"p-value: {pvalue:.5f}\")\n",
    "# p-value: 0.00523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeaa1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "nk = 50  # 50 nodes per community\n",
    "K = 2  # the number of communities\n",
    "n = nk * K  # total number of nodes\n",
    "\n",
    "zs = np.repeat(np.arange(1, K+1), repeats=nk)\n",
    "# block matrix\n",
    "B = np.array([[0.6, 0.3],[0.3, 0.5]])\n",
    "# generate network sample\n",
    "np.random.seed(0)\n",
    "A = sbm([nk, nk], B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.models import SBMEstimator\n",
    "\n",
    "# instantiate the class object and fit\n",
    "model = SBMEstimator(directed=False, loops=False)\n",
    "model.fit(A, y=zs)\n",
    "# obtain the estimate of the block matrix\n",
    "Bhat = model.block_p_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upper left has a value of 1, lower right has a value of 2,\n",
    "# and upper right, bottom left have a value of 3\n",
    "Z = np.array(zs).reshape(n, 1) @ np.array(zs).reshape(1, n)\n",
    "# make lower right have a value of 3\n",
    "Z[Z == 4] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04127347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats as spstat\n",
    "\n",
    "# upper triangle since the network is simple (undirected and loopless)\n",
    "upper_tri_non_diag = np.triu(np.ones(A.shape), k=1).astype(bool)\n",
    "\n",
    "df_H1 = pd.DataFrame({\"Value\" : A[upper_tri_non_diag],\n",
    "            \"Group\": (Z[upper_tri_non_diag] != 2).astype(int)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the logistic regression model, regressing the outcome (edge or no edge)\n",
    "# onto the edge group (on-diagonal or off-diagonal), the grouping\n",
    "# corresponding to H1\n",
    "model_H1 = smf.logit(\"Value ~ C(Group)\", df_H1).fit()\n",
    "\n",
    "# compare the likelihood ratio statistic to the chi2 distribution\n",
    "# with 1 dof to see the fraction that is less than l1\n",
    "dof = 1\n",
    "print(f\"p-value: {spstat.chi2.sf(model_H1.llr, dof):.3f}\")\n",
    "# p-value: 0.00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6562bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_H2 = pd.DataFrame({\"Value\": A[upper_tri_non_diag],\n",
    "                      \"Group\": Z[upper_tri_non_diag].astype(int)})\n",
    "model_H2 = smf.logit(\"Value ~ C(Group)\", df_H2).fit()\n",
    "lr_stat_H2vsH1 = model_H2.llr - model_H1.llr\n",
    "print(f\"p-value: {spstat.chi2.sf(lr_stat_H2vsH1, 1):.7f}\")\n",
    "# 0.00008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501d707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "# first 100 nodes are traffickers, second 900 are non-traffickers\n",
    "ns = [100, 900]\n",
    "B = np.array([[0.3, 0.1], [0.1, 0.2]])\n",
    "np.random.seed(0)\n",
    "A = sbm(ns, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6d8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of seed nodes\n",
    "nseeds = 20\n",
    "# The first ns[0] nodes are the human traffickers, so choose 20 seeds\n",
    "# at random\n",
    "seed_ids = np.random.choice(ns[0], size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c491471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ase\n",
    "\n",
    "Xhat = ase(n_components=2, svd_seed=0).fit_transform(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfa8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# community detection with kmeans\n",
    "km_clust = KMeans(n_clusters=2, random_state=0)\n",
    "km_clust.fit(Xhat)\n",
    "labels_kmeans = km_clust.fit_predict(Xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphbook_code import ohe_comm_vec\n",
    "\n",
    "# estimated community assignment matrix\n",
    "Chat = ohe_comm_vec(labels_kmeans)\n",
    "\n",
    "# get the community (class) with the most seeds\n",
    "comm_of_seeds = np.argmax(Chat[seed_ids,:].sum(axis=0))\n",
    "\n",
    "# get centroid of the community that seeds tend to be\n",
    "# assigned to\n",
    "centroid_seeds = km_clust.cluster_centers_[comm_of_seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# compute the distance to the centroid for all estimated latent positions\n",
    "dists_to_centroid = cdist(Xhat, centroid_seeds.reshape(1, -1)).reshape(-1)\n",
    "# compute the node numbers for all the nonseed nodes\n",
    "nonseed_bool = np.ones((np.sum(ns)))\n",
    "nonseed_bool[seed_ids] = 0\n",
    "nonseed_ids = np.array(np.where(nonseed_bool)).reshape(-1)\n",
    "\n",
    "# isolate the distances to the centroid for the nonseed nodes\n",
    "nonseed_dists = dists_to_centroid[nonseed_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the nomination list\n",
    "nom_list_nonseeds = np.argsort(nonseed_dists).reshape(-1)\n",
    "# obtain a nomination list in terms of the original node ids\n",
    "nom_list = nonseed_ids[nom_list_nonseeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sbm\n",
    "\n",
    "# the in-sample nodes\n",
    "n = 100\n",
    "nk = 50\n",
    "# the out-of-sample nodes\n",
    "np1 = 1; np2 = 2\n",
    "B = np.array([[0.6, 0.2], [0.2, 0.4]])\n",
    "# sample network\n",
    "np.random.seed(0)\n",
    "A, zs = sbm([nk + np1, nk + np2], B, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8979b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import remove_vertices\n",
    "\n",
    "# the indices of the out-of-sample nodes\n",
    "oos_idx = [nk, nk + np1 + nk, nk + np1 + nk + 1]\n",
    "# get adjacency matrix and the adjacency vectors A prime\n",
    "Ain, Aoos = remove_vertices(A, indices=oos_idx, return_removed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.embed import AdjacencySpectralEmbed as ase\n",
    "\n",
    "oos_embedder = ase()\n",
    "# estimate latent positions for the in-sample nodes\n",
    "# using the subnetwork induced by the in-sample nodes\n",
    "Xhat_in = oos_embedder.fit_transform(Ain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d365f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xhat_oos = oos_embedder.transform(Aoos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
