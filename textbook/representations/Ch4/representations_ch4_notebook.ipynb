{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "62c6c9e4",
      "cell_type": "markdown",
      "source": "(ch4:code_repr)=\n# Code Reproducibility",
      "metadata": {}
    },
    {
      "id": "c75bddff",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nfrom graphbook_code import heatmap\n\ndef generate_unit_circle(radius):\n    diameter = 2*radius + 1\n    rx = ry = diameter/2\n    x, y = np.indices((diameter, diameter))\n\n    circle_dist = np.hypot(rx - x, ry - y)\n    diff_from_radius = np.abs(circle_dist - radius)\n    less_than_half = diff_from_radius < 0.5\n\n    return less_than_half.astype(int)\n\ndef add_smile():\n    canvas = np.zeros((51, 51))\n    canvas[2:45, 2:45] = generate_unit_circle(21)\n    mask = np.zeros((51, 51), dtype=bool)\n    mask[np.triu_indices_from(mask)] = True\n    upper_left = np.rot90(mask)\n    canvas[upper_left] = 0\n    return canvas\n    \ndef smile_probability(upper_p, lower_p):\n    smiley = add_smile()\n    P = generate_unit_circle(25)\n    P[5:16, 25:36] = generate_unit_circle(5)\n    P[smiley != 0] = smiley[smiley != 0]\n    \n    mask = np.zeros((51, 51), dtype=bool)\n    mask[np.triu_indices_from(mask)] = True\n    P[~mask] = 0\n    # symmetrize the probability matrix\n    P = (P + P.T - np.diag(np.diag(P))).astype(float)\n    P[P == 1] = lower_p\n    P[P == 0] = upper_p\n    return P\n\nP = smile_probability(.95, 0.05)\nheatmap(P, vmin=0, vmax=1, title=\"Probability matrix $P$\")",
      "outputs": []
    },
    {
      "id": "14babe95",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import sample_edges\n\nA = sample_edges(P, directed=False, loops=False)\nheatmap(A.astype(int), title=\"$IER_n(P)$ sample\")",
      "outputs": []
    },
    {
      "id": "7bc2a4a3",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nfrom math import comb\n\nnode_count = np.arange(2, 51)\nlog_unique_network_count = np.array([comb(n, 2) for n in node_count])*np.log10(2)",
      "outputs": []
    },
    {
      "id": "3be7d62d",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import draw_multiplot\nfrom graspologic.simulations import er_np\n\nn = 50  # network with 50 nodes\np = 0.3  # probability of an edge existing is .3\n\n# sample a single simple adjacency matrix from ER(50, .3)\nA = er_np(n=n, p=p, directed=False, loops=False)\n\n# and plot it\ndraw_multiplot(A.astype(int), title=\"$ER_{50}(0.3)$ Simulation\")",
      "outputs": []
    },
    {
      "id": "a186da0e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "p = 0.7  # network has an edge probability of 0.7\n\n# sample a single adjacency matrix from ER(50, 0.7)\nA = er_np(n=n, p=p, directed=False, loops=False)",
      "outputs": []
    },
    {
      "id": "46e2a8b9",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import plot_vector\nimport numpy as np\n\nn = 100  # number of students\n\n# z is a column vector of 50 1s followed by 50 2s\n# this vector gives the school each of the 100 students are from\nz = np.repeat([1, 2], repeats=n//2)\nplot_vector(z, title=\"$\\\\vec z$, Node Assignment Vector\",\n            legend_title=\"School\", color=\"qualitative\", \n            ticks=[0.5, 49.5, 99.5], ticklabels=[1, 50, 100],\n            ticktitle=\"Student\")",
      "outputs": []
    },
    {
      "id": "326cf1ec",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import heatmap\n\nK = 2  # community count\n# construct the block matrix B as described above\nB = np.array([[0.6, 0.1], \n              [0.1, 0.4]])\n\nheatmap(B, xticklabels=[1, 2], yticklabels=[1,2], vmin=0, \n             vmax=1, annot=True, xtitle=\"School\",\n             ytitle=\"School\", title=\"Block Matrix $B$\")",
      "outputs": []
    },
    {
      "id": "a69dcbe1",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import sbm\nfrom graphbook_code import draw_multiplot\n\n# sample a graph from SBM_{100}(tau, B)\nA, labels = sbm(n=[n//2, n//2], p=B, directed=False, loops=False, return_labels=True)\ndraw_multiplot(A, labels=labels, title=\"$SBM_n(z, B)$ Simulation\");",
      "outputs": []
    },
    {
      "id": "6bad2600",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\n\n# generate a reordering of the n nodes\npermutation = np.random.choice(n, size=n, replace=False)\n\nAperm = A[permutation][:,permutation]\nyperm = labels[permutation]\nheatmap(Aperm, title=\"Nodes randomly reordered\")",
      "outputs": []
    },
    {
      "id": "fc76bdd4",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "def ohe_comm_vec(z):\n    \"\"\"\n    A function to generate the one-hot-encoded community\n    assignment matrix from a community assignment vector.\n    \"\"\"\n    K = len(np.unique(z))\n    n = len(z)\n    C = np.zeros((n, K))\n    for i, zi in enumerate(z):\n        C[i, zi - 1] = 1\n    return C",
      "outputs": []
    },
    {
      "id": "ca432add",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nfrom graphbook_code import lpm_heatmap\n\nn = 100  # the number of nodes in our network\n# design the latent position matrix X according to \n# the rules we laid out previously\nX = np.zeros((n,2))\nfor i in range(0, n):\n    X[i,:] = [(n - i)/n, i/n]\n\nlpm_heatmap(X, ytitle=\"Person\", xticks=[0.5, 1.5], xticklabels=[1, 2], \n            yticks=[0.5, 49.5, 99.5], yticklabels=[1, 50, 100],\n            xtitle=\"Latent Dimension\", title=\"Latent Position Matrix, X\")",
      "outputs": []
    },
    {
      "id": "34be4120",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import rdpg\nfrom graphbook_code import heatmap\n\n# sample an RDPG with the latent position matrix\n# created above\nA = rdpg(X, loops=False, directed=False)\n\n# and plot it\nheatmap(A.astype(int), xtitle=\"Person\", ytitle=\"Person\",\n        title=\"$RDPG_{100}(X)$ Simulation\")",
      "outputs": []
    },
    {
      "id": "07625635",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\n\ndef block_mtx_psd(B):\n    \"\"\"\n    A function which indicates whether a matrix\n    B is positive semidefinite.\n    \"\"\"\n    return np.all(np.linalg.eigvals(B) >= 0)",
      "outputs": []
    },
    {
      "id": "ffc3fc15",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nfrom graphbook_code import heatmap\n\nB = np.array([[0.6, 0.2], \n              [0.2, 0.4]])\nheatmap(B, title=\"A homophilic block matrix\", annot=True, vmin=0, vmax=1)\nblock_mtx_psd(B)\n# True",
      "outputs": []
    },
    {
      "id": "367c3748",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "B_indef = np.array([[.1, .2], \n                    [.2, .1]])\nblock_mtx_psd(B_indef)\n# False",
      "outputs": []
    },
    {
      "id": "1f81b3e2",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# a positive semidefinite kidney-egg block matrix\nB_psd = np.array([[.6, .2], \n                  [.2, .2]])\nblock_mtx_psd(B_psd)\n# True\n\n# an indefinite kidney-egg block matrix\nB_indef = np.array([[.1, .2], \n                    [.2, .2]])\nblock_mtx_psd(B_indef)\n#False",
      "outputs": []
    },
    {
      "id": "e105bdee",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# a positive semidefinite core-periphery block matrix\nB_psd = np.array([[.6, .2], \n                  [.2, .1]])\nblock_mtx_psd(B_psd)\n# True\n\n# an indefinite core-periphery block matrix\nB_indef = np.array([[.6, .2], \n                    [.2, .05]])\nblock_mtx_psd(B_indef)\n# False",
      "outputs": []
    },
    {
      "id": "0a303a47",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# an indefinite disassortative block matrix\nB = np.array([[.1, .5], \n              [.5, .2]])\nblock_mtx_psd(B)\n# False",
      "outputs": []
    },
    {
      "id": "8fe341a2",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# homophilic, and hence positive semidefinite, block matrix\nB = np.array([[0.6, 0.2], \n              [0.2, 0.4]])\n\n# generate square root matrix\nsqrtB = np.linalg.cholesky(B)\n\n# verify that the process worked through by equality element-wise\n# use allclose instead of array_equal because of tiny\n# numerical precision errors\nnp.allclose(sqrtB @ sqrtB.T, B)\n# True",
      "outputs": []
    },
    {
      "id": "06ee3c06",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import ohe_comm_vec\n\ndef lpm_from_sbm(z, B):\n    \"\"\"\n    A function to produce a latent position matrix from a\n    community assignment vector and a block matrix.\n    \"\"\"\n    if not block_mtx_psd(B):\n        raise ValueError(\"Latent position matrices require PSD block matrices!\")\n    # one-hot encode the community assignment vector\n    C = ohe_comm_vec(z)\n    # compute square root matrix\n    sqrtB = np.linalg.cholesky(B)\n    # X = C*sqrt(B)\n    return C @ sqrtB\n\n# make a community assignment vector for 25 nodes / community\nnk = 25\nz = np.repeat([1, 2], nk)\n\n# latent position matrix for an equivalent RDPG\nX = lpm_from_sbm(z, B)",
      "outputs": []
    },
    {
      "id": "339f1567",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import generate_sbm_pmtx\n\n# generate the probability matrices for an RDPG using X and SBM\nP_rdpg = X @ X.T\nP_sbm = generate_sbm_pmtx(z, B)\n\n# verify equality element-wise\nnp.allclose(P_rdpg, P_sbm)\n# True",
      "outputs": []
    },
    {
      "id": "5122781c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nfrom graspologic.simulations import sample_edges\nfrom graphbook_code import heatmap, plot_vector, \\\n    generate_sbm_pmtx\n\ndef dcsbm(z, theta, B, directed=False, loops=False, return_prob=False):\n    \"\"\"\n    A function to sample a DCSBM.\n    \"\"\"\n    # uncorrected probability matrix\n    Pp = generate_sbm_pmtx(z, B)\n    theta = theta.reshape(-1)\n    # apply the degree correction\n    Theta = np.diag(theta)\n    P = Theta @ Pp @ Theta.transpose()\n    network = sample_edges(P, directed=directed, loops=loops)\n    if return_prob:\n        network = (network, P)\n    return network",
      "outputs": []
    },
    {
      "id": "07f60921",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# Observe a network from a DCSBM\nnk = 50  # students per school\nz = np.repeat([1, 2], 50)\nB = np.array([[0.6, 0.2], [0.2, 0.4]])  # same probabilities as from SBM section\ntheta = np.tile(np.linspace(1, 0.5, nk), 2)\nA, P = dcsbm(z, theta, B, return_prob=True)\n\n# Visualize\nplot_vector(z, title=\"$\\\\vec z$\", legend_title=\"School\", color=\"qualitative\", \n            ticks=[0.5, 49.5, 99.5], ticklabels=[1, 50, 100],\n            ticktitle=\"Student\")\nplot_vector(theta, title=\"$\\\\vec \\\\theta$\", \n            legend_title=\"Degree-Correction Factor\", \n            ticks=[0.5, 49.5, 99.5], ticklabels=[1, 50, 100],\n            ticktitle=\"Student\")\nheatmap(P, title=\"$P = \\\\Theta C B C^\\\\top \\\\Theta^\\\\top$\", vmin=0, vmax=1)\nheatmap(A.astype(int), title=\"Sample of $DCSBM_n(\\\\vec z, \\\\vec \\\\theta, B)$\")",
      "outputs": []
    },
    {
      "id": "3eacd45c",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\n\nn = 100\nZ = np.ones((n, n))\nfor i in range(0, int(n / 2)):\n    Z[int(i + n / 2), i] = 3\n    Z[i, int(i + n / 2)] = 3\nZ[0:50, 0:50] = Z[50:100, 50:100] = 2\nnp.fill_diagonal(Z, 0)",
      "outputs": []
    },
    {
      "id": "54ec5f54",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import heatmap\n\nlabels = np.repeat([\"L\", \"R\"], repeats=n/2)\nheatmap(Z.astype(int), title=\"Cluster assignment matrix\", \n        inner_hier_labels=labels)",
      "outputs": []
    },
    {
      "id": "ef05515a",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import siem, plot_vector\n\np = np.array([0.1, 0.3, 0.8])\nA = siem(n, p, Z)\nplot_vector(p, title=\"probability vector\", vmin=0, vmax=1, annot=True)\nheatmap(A.astype(int), title=\"$SIEM_n(Z, \\\\vec p)$ sample\", \n        inner_hier_labels=labels)",
      "outputs": []
    },
    {
      "id": "90b46157",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import sbm\nimport numpy as np\nfrom graphbook_code import dcsbm\nfrom sklearn.preprocessing import LabelEncoder\n\n# Create block probability matrix B\nK = 3\nB = np.full(shape=(K, K), fill_value=0.15)\nnp.fill_diagonal(B, 0.4)\n\n# degree-correct the different groups for linkedin\nml, admin, marketing = nks = [50, 25, 25]\ntheta = np.ones((np.sum(nks), 1))\ntheta[(ml):(ml + admin), :] = np.sqrt(2)\n\n# our dcsbm function only works with communities encoded 1,2,...,K\n# so we'll use a LabelEncoder to map labels to natural numbers\nlabels = np.repeat([\"ML\", \"AD\", \"MA\"], nks)\nle = LabelEncoder().fit(labels)\nz = le.transform(labels) + 1\n\n# sample the random networks\nA_facebook = sbm(n=nks, p=B)\nA_insta = sbm(n=nks, p=B)\nA_linkedin, P_linkedin = dcsbm(z, theta, B, return_prob=True)",
      "outputs": []
    },
    {
      "id": "fe96eee6",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import generate_sbm_pmtx, heatmap\n\n# we already returned P_linkedin for the linkedin\n# probability matrix from dcsbm() function\nP_facebook_insta = generate_sbm_pmtx(z, B)\n\n# when plotting for comparison purposes, make sure you are\n# using the same scale from 0 to 1\nheatmap(P_facebook_insta, vmin=0, vmax=1)\nheatmap(P_linkedin, vmin=0, vmax=1)\nheatmap(P_linkedin - P_facebook_insta, vmin=0, vmax=1)",
      "outputs": []
    },
    {
      "id": "bdf1d304",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.embed import MultipleASE as mase\nfrom graphbook_code import lpm_heatmap\n\nembedder = mase(n_components=3, svd_seed=0)\n# obtain shared latent positions\nS = embedder.fit_transform([P_facebook_insta, P_facebook_insta, P_linkedin])\n\nlpm_heatmap(S)",
      "outputs": []
    },
    {
      "id": "b786ae13",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import matplotlib.pyplot as plt\n\nR_facebook = embedder.scores_[0]\nR_insta = embedder.scores_[1]\nR_linkedin = embedder.scores_[2]\n\n# and plot them\nsmin = np.min(embedder.scores_)\nsmax = np.max(embedder.scores_)\n\nfig, axs = plt.subplots(1, 3, figsize=(20, 7))\nheatmap(R_facebook, vmin=smin, vmax=smax, ax=axs[0], annot=True, title=\"facebook score matrix\")\nheatmap(R_insta, vmin=smin, vmax=smax, ax=axs[1], annot=True, title=\"Instagram score matrix\")\nheatmap(R_linkedin, vmin=smin, vmax=smax, ax=axs[2], annot=True, title=\"LinkedIn score matrix\")",
      "outputs": []
    },
    {
      "id": "8ceb3a52",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graphbook_code import lpm_from_sbm\nX_facebook_insta = lpm_from_sbm(z, B)",
      "outputs": []
    },
    {
      "id": "ea7133a7",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from graspologic.simulations import rdpg_corr\n\n# generate the network samples\nrho = 0.7\nfacebook_correlated_network, insta_correlated_network = rdpg_corr(\n    X_facebook_insta, Y=None, r=rho\n)\n\n# the difference matrix\ncorrelated_difference_matrix = np.abs(\n    facebook_correlated_network - insta_correlated_network\n)\n# the total number of differences\ncorrelated_differences = correlated_difference_matrix.sum()",
      "outputs": []
    },
    {
      "id": "fe9ef84a",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "rho_nil = 0.0\nfacebook_uncorrelated_network, insta_uncorrelated_network = rdpg_corr(\n    X_facebook_insta, Y=None, r=rho_nil\n)\n\n# the difference matrix\nuncorrelated_difference_matrix = np.abs(\n    facebook_uncorrelated_network - insta_uncorrelated_network\n)\n# the total number of differences\nuncorrelated_differences = uncorrelated_difference_matrix.sum()",
      "outputs": []
    },
    {
      "id": "02cd7231",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nfrom graspologic.simulations import sample_edges\n\nnodenames = [\n    \"SI\", \"L\", \"H/E\", \n    \"T/M\", \"BS\"\n]\n\n# generate probability matrices\nn = 5  # the number of nodes\nP_earthling = 0.3*np.ones((n, n))\nsignal_subnetwork = np.zeros((n, n), dtype=bool)\nsignal_subnetwork[1:n, 0] = True\nsignal_subnetwork[0, 1:n] = True\nP_astronaut = np.copy(P_earthling)\nP_astronaut[signal_subnetwork] = np.tile(np.linspace(0.4, 0.9, num=4), 2)\n\n# sample two networks\nA_earthling = sample_edges(P_earthling)\nA_astronaut = sample_edges(P_astronaut)",
      "outputs": []
    },
    {
      "id": "fc11647f",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# plot probability matrices and their differences on the same scale\nheatmap(P_earthling, vmin=0, vmax=1)\nheatmap(P_astronaut, vmin=0, vmax=1)\nheatmap(np.abs(P_astronaut - P_earthling), vmin=0, vmax=1)",
      "outputs": []
    },
    {
      "id": "35c1b0e5",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# plot the signal subnetwork\nax = heatmap(signal_subnetwork)",
      "outputs": []
    },
    {
      "id": "50c9aeeb",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "# sample the classes of each sample\nM = 200  # the number of training and testing samples\npi_astronaut = 0.45\npi_earthling = 0.55\nnp.random.seed(0)\nyvec = np.random.choice(2, p=[pi_earthling, pi_astronaut], size=M)\n\n# sample network realizations given the class of each sample\nPs = [P_earthling, P_astronaut]\n\nAs = np.stack([sample_edges(Ps[y]) for y in yvec], axis=2)",
      "outputs": []
    }
  ]
}