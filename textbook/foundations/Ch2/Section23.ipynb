{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20023683-939b-4ce1-aabf-7a628d0f03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"svg\"  # output format for figs\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "font = {'family' : 'Dejavu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a56ee6-7a09-4b62-ab36-15b91fea621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "from graspologic.utils import import_edgelist\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# the AWS bucket the data is stored in\n",
    "BUCKET_ROOT = \"open-neurodata\"\n",
    "parcellation = \"Schaefer400\"\n",
    "FMRI_PREFIX = \"m2g/Functional/BNU1-11-12-20-m2g-func/Connectomes/\" + parcellation + \"_space-MNI152NLin6_res-2x2x2.nii.gz/\"\n",
    "FMRI_PATH = os.path.join(\"datasets\", \"fmri\")  # the output folder\n",
    "DS_KEY = \"abs_edgelist\"  # correlation matrices for the networks to exclude\n",
    "\n",
    "def fetch_fmri_data(bucket=BUCKET_ROOT, fmri_prefix=FMRI_PREFIX,\n",
    "                    output=FMRI_PATH, name=DS_KEY):\n",
    "    \"\"\"\n",
    "    A function to fetch fMRI connectomes from AWS S3.\n",
    "    \"\"\"\n",
    "    # check that output directory exists\n",
    "    if not os.path.isdir(FMRI_PATH):\n",
    "        os.makedirs(FMRI_PATH)\n",
    "    # start boto3 session anonymously\n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    # obtain the filenames\n",
    "    bucket_conts = s3.list_objects(Bucket=bucket, \n",
    "                    Prefix=fmri_prefix)[\"Contents\"]\n",
    "    for s3_key in tqdm(bucket_conts):\n",
    "        # get the filename\n",
    "        s3_object = s3_key['Key']\n",
    "        # verify that we are grabbing the right file\n",
    "        if name not in s3_object:\n",
    "            op_fname = os.path.join(FMRI_PATH, str(s3_object.split('/')[-1]))\n",
    "            if not os.path.exists(op_fname):\n",
    "                s3.download_file(bucket, s3_object, op_fname)\n",
    "\n",
    "def read_fmri_data(path=FMRI_PATH):\n",
    "    \"\"\"\n",
    "    A function which loads the connectomes as adjacency matrices.\n",
    "    \"\"\"\n",
    "    # import edgelists with graspologic\n",
    "    # edgelists will be all of the files that end in a csv\n",
    "    networks = [import_edgelist(fname) for fname in tqdm(glob.glob(os.path.join(path, \"*.csv\")))]\n",
    "    return np.stack(networks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513e6d6-3dfd-47a5-a80e-d4727d8d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_fmri_data()\n",
    "As = read_fmri_data()\n",
    "A = As[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f073c3-9ed4-47ae-9bf0-b08ed5a9d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_isolates(A):\n",
    "    \"\"\"\n",
    "    A function which removes isolated nodes from the \n",
    "    adjacency matrix A.\n",
    "    \"\"\"\n",
    "    degree = A.sum(axis=0)  # sum along the rows to obtain the node degree\n",
    "    out_degree = A.sum(axis=1)\n",
    "    A_purged = A[~(degree == 0),:]\n",
    "    A_purged = A_purged[:,~(degree == 0)]\n",
    "    print(\"Purging {:d} nodes...\".format((degree == 0).sum()))\n",
    "    return A_purged\n",
    "    \n",
    "A = remove_isolates(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84c2ff-6f45-4603-a488-d8c51af6f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from graphbook_code import heatmap\n",
    "\n",
    "A_abs = np.abs(A)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(21, 6))\n",
    "heatmap(A, ax=axs[0], title=\"(A) Human Connectome, Raw\", vmin=np.min(A), vmax=1)\n",
    "heatmap(A_abs, ax=axs[1], title=\"(B) Human Connectome, Absolute\", vmin=np.min(A), vmax=1)\n",
    "heatmap(A_abs - A, ax=axs[2], title=\"(C) Difference(Absolute - Raw)\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e90bf-107b-4b5d-9dee-69466104ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class CleanData(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(\"Cleaning data...\")\n",
    "        Acleaned = remove_isolates(X)\n",
    "        A_abs_cl = np.abs(Acleaned)\n",
    "        self.A_ = A_abs_cl\n",
    "        return self.A_\n",
    "\n",
    "data_cleaner = CleanData()\n",
    "A_clean = data_cleaner.transform(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c507182-124b-41d0-9ab4-48aaf9ae45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import binarize\n",
    "\n",
    "threshold = 0.4\n",
    "A_bin = binarize(A_clean > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70073501-0f79-491b-a0ff-e9cc43a5cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from graspologic.utils import pass_to_ranks\n",
    "\n",
    "A_ptr = pass_to_ranks(A_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a0a361-03f4-4526-848c-4ac4c9f4986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtick = [0, 199, 399]; ytick = xtick\n",
    "xlabs = [1, 200, 400]; ylabs = xlabs\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(18, 5))\n",
    "heatmap(A, ax=axs[0], title=\"(A) Raw Connectome\", vmin=-1, vmax=1, xticks=xtick, xticklabels=xlabs, \n",
    "        yticks=ytick, yticklabels=ylabs, xtitle=\"Brain Area\", ytitle=\"Brain Area\")\n",
    "heatmap(A_bin.astype(int), ax=axs[1], title=\"(B) Binarized Connectome\", xticks=xtick, xticklabels=xlabs, \n",
    "        yticks=ytick, yticklabels=ylabs, xtitle=\"Brain Area\", ytitle=\"Brain Area\")\n",
    "heatmap(A_ptr, ax=axs[2], title=\"(C) Ranked Connectome\", vmin=0, vmax=1, xticks=xtick, xticklabels=xlabs, \n",
    "        yticks=ytick, yticklabels=ylabs, xtitle=\"Brain Area\", ytitle=\"Brain Area\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "fname = \"cleaning_connectomes\"\n",
    "if mode != \"png\":\n",
    "    os.makedirs(f\"Figures/{mode:s}\", exist_ok=True)\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "    \n",
    "os.makedirs(\"Figures/png\", exist_ok=True)\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bcc6eb-53df-4f81-a9a0-5f4d05b45768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize=(10, 10))\n",
    "sns.histplot(A_clean[A_clean > 0].flatten(), ax=axs[0], color=\"gray\")\n",
    "axs[0].set_xlabel(\"Edge weight\")\n",
    "axs[0].set_title(\"(A) Histogram of human connectome, \\n non-zero edge weights\")\n",
    "\n",
    "sns.histplot(A_ptr[A_ptr > 0].flatten(), ax=axs[1], color=\"gray\")\n",
    "axs[1].set_xlabel(\"ptr(Edge weight)\")\n",
    "axs[1].set_title(\"(B) Histogram of human connectome, \\n passed-to-ranks\")\n",
    "fig.tight_layout()\n",
    "\n",
    "fname = \"ptrhists\"\n",
    "if mode != \"png\":\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd1f41e-9b07-4957-85ae-78ce19dc1087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        print(\"Scaling edge-weights...\")\n",
    "        A_scaled = pass_to_ranks(X)\n",
    "        return (A_scaled)\n",
    "    \n",
    "feature_scaler = FeatureScaler()\n",
    "A_cleaned_scaled = feature_scaler.transform(A_clean)\n",
    "# Scaling edge-weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e053a99-e6bb-45d0-b2e7-747ebf12f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('cleaner', CleanData()),\n",
    "    ('scaler', FeatureScaler()),\n",
    "])\n",
    "\n",
    "A_xfm = num_pipeline.fit_transform(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a606e-bf57-4a5e-958a-3f03adc3b289",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_xfm2 = num_pipeline.fit_transform(As[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077515f-3adc-48ed-ac66-608243612157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
