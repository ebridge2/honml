{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {},
  "cells": [
    {
      "id": "543e4dea",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\n\np = np.linspace(.02, .98, num=49)\nnflips = 10; nheads = 6\nlikelihood = p**(nheads)*(1 - p)**(nflips - nheads)",
      "outputs": []
    },
    {
      "id": "5924b8da",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "loglikelihood = nheads*np.log(p) + (nflips - nheads)*np.log(1 - p)",
      "outputs": []
    },
    {
      "id": "c31529b4",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import scipy as sp\n\n# simulation of 1000 values from the N(0,1) distn\nn = 1000\nxs = np.random.normal(loc=0, scale=1, size=n)\nys = np.random.normal(loc=0, scale=1, size=n)\n# compute the square\nxssq = xs**2\nyssq = ys**2\nsum_xsq_ysq = xssq + yssq\n\n# compute the centers for bin histograms from 0 to maxval in\n# 30 even bins\nnbins = 30\nbincenters = np.linspace(start=0, stop=np.max(sum_xsq_ysq), num=nbins)\n\n# compute the pdf of the chi-squared distribution for X^2 + Y^2, which when\n# X, Y are N(0, 1), is Chi2(2), the chi-squared distn with 2 degrees of freedom\ndof = 2\ntrue_pdf = sp.stats.chi2.pdf(bincenters, dof)",
      "outputs": []
    },
    {
      "id": "48e369f7",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "print(\"Approximate mean: {:2f}\".format(np.mean(sum_xsq_ysq)))\n# mean of chi-squared is just its degrees of freedom; here, 2\nprint(\"True mean: {:2f}\".format(2))",
      "outputs": []
    },
    {
      "id": "fd218fb3",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import graspologic as gp\n\nn = 10  # number of nodes\nnsims = 200  # number of networks to simulate\np = 0.4\n\n# realizations\nAs = [gp.simulations.er_np(n, p, directed=False, loops=False) for i in range(0, nsims)]\n# fit ER models\nfit_models = [gp.models.EREstimator(directed=False, loops=False).fit(A) for A in As]\nhatps = [model.p_ for model in fit_models]  # the probability parameters",
      "outputs": []
    },
    {
      "id": "f45e05cd",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "from pandas import DataFrame\nns = [8, 16, 32, 64, 128]\nnsims = 200\np = 0.4\nresults = []\nfor n in ns:\n  for i in range(0, nsims):\n    A = gp.simulations.er_np(n, p, directed=False, loops=False)\n    phatni = gp.models.EREstimator(directed=False, loops=False).fit(A).p_\n    results.append({\"n\": n, \"i\": i, \"phat\": phatni})\nres_df = DataFrame(results)\nres_df[\"diff\"] = np.abs(res_df[\"phat\"] - p)",
      "outputs": []
    },
    {
      "id": "2b308693",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import numpy as np\nfrom graspologic.simulations import er_np\nfrom graspologic.embed import AdjacencySpectralEmbed\n\ndef orthogonal_align(Xhat, p=0.5):\n    return -Xhat if ((Xhat*np.sqrt(p)).sum() < 0) else Xhat\n\np = 0.5\nns = np.round(10**np.linspace(1.5, 3.5, 5)).astype(int)\nase = AdjacencySpectralEmbed(n_components=1)\n\nnrep = 50\nAs = [[er_np(n, p) for _ in range(nrep)] for n in ns]\nXhats_aligned = [[orthogonal_align(ase.fit_transform(A)) for A in An] for An in As]",
      "outputs": []
    },
    {
      "id": "153af329",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import pandas as pd\n\ndata = []\nfor n_idx, n in enumerate(ns):\n    for j in range(50):\n        data.extend([(Xhats_aligned[n_idx][j][i][0], i, n, j, np.sqrt(p)) for i in range(n)])\n\ndf = pd.DataFrame(data, columns=[\"Xhat\", \"i\", \"n\", \"j\", \"X\"])\ndf[\"abs_diff\"] = np.abs(df[\"Xhat\"] - df[\"X\"])\n\nmax_pernet = df.groupby([\"n\", \"j\"])[\"abs_diff\"].max().reset_index()\nmax_pernet[\"norm_factor\"] = np.log(max_pernet[\"n\"])**2 / np.sqrt(max_pernet[\"n\"])\nmax_pernet[\"norm_diff\"] = max_pernet[\"abs_diff\"] / max_pernet[\"norm_factor\"]",
      "outputs": []
    },
    {
      "id": "40b54d7e",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "df_reduced = df[df[\"j\"] == 0].copy()\ndf_reduced[\"limiting_factor\"] = np.sqrt(df_reduced[\"n\"]) * (df_reduced[\"Xhat\"] - df_reduced[\"X\"])",
      "outputs": []
    }
  ]
}