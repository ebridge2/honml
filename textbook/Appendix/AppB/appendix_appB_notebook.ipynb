{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74141f02-7d16-419b-acc1-829dc15c311f",
   "metadata": {},
   "source": [
    "# Code Reproducibility: Appendix B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdbdd4-8292-4c2f-bbea-114c4ae2c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = np.linspace(.02, .98, num=49)\n",
    "nflips = 10; nheads = 6\n",
    "likelihood = p**(nheads)*(1 - p)**(nflips - nheads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b833fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood = nheads*np.log(p) + (nflips - nheads)*np.log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "# simulation of 1000 values from the N(0,1) distn\n",
    "n = 1000\n",
    "xs = np.random.normal(loc=0, scale=1, size=n)\n",
    "ys = np.random.normal(loc=0, scale=1, size=n)\n",
    "# compute the square\n",
    "xssq = xs**2\n",
    "yssq = ys**2\n",
    "sum_xsq_ysq = xssq + yssq\n",
    "\n",
    "# compute the centers for bin histograms from 0 to maxval in\n",
    "# 30 even bins\n",
    "nbins = 30\n",
    "bincenters = np.linspace(start=0, stop=np.max(sum_xsq_ysq), num=nbins)\n",
    "\n",
    "# compute the pdf of the chi-squared distribution for X^2 + Y^2, which when\n",
    "# X, Y are N(0, 1), is Chi2(2), the chi-squared distn with 2 degrees of freedom\n",
    "dof = 2\n",
    "true_pdf = sp.stats.chi2.pdf(bincenters, dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c67c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Approximate mean: {:2f}\".format(np.mean(sum_xsq_ysq)))\n",
    "# mean of chi-squared is just its degrees of freedom; here, 2\n",
    "print(\"True mean: {:2f}\".format(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc13f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graspologic as gp\n",
    "\n",
    "n = 10  # number of nodes\n",
    "nsims = 200  # number of networks to simulate\n",
    "p = 0.4\n",
    "\n",
    "# realizations\n",
    "As = [gp.simulations.er_np(n, p, directed=False, loops=False) for i in range(0, nsims)]\n",
    "# fit ER models\n",
    "fit_models = [gp.models.EREstimator(directed=False, loops=False).fit(A) for A in As]\n",
    "hatps = [model.p_ for model in fit_models]  # the probability parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafa3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from graspologic.models import EREstimator\n",
    "ns = [8, 16, 32, 64, 128]\n",
    "nsims = 200\n",
    "p = 0.4\n",
    "results = []\n",
    "for n in ns:\n",
    "  for i in range(0, nsims):\n",
    "    A = er_np(n, p, directed=False, loops=False)\n",
    "    phatni = EREstimator(directed=False, loops=False).fit(A).p_\n",
    "    results.append({\"n\": n, \"i\": i, \"phat\": phatni})\n",
    "res_df = DataFrame(results)\n",
    "res_df[\"diff\"] = np.abs(res_df[\"phat\"] - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import er_np\n",
    "from graspologic.embed import AdjacencySpectralEmbed\n",
    "\n",
    "def orthogonal_align(Xhat, p=0.5):\n",
    "    return -Xhat if ((Xhat*np.sqrt(p)).sum() < 0) else Xhat\n",
    "\n",
    "p = 0.5\n",
    "ns = np.round(10**np.linspace(1.5, 3.5, 5)).astype(int)\n",
    "ase = AdjacencySpectralEmbed(n_components=1)\n",
    "\n",
    "nrep = 50\n",
    "As = [[er_np(n, p) for _ in range(nrep)] for n in ns]\n",
    "Xhats_aligned = [[orthogonal_align(ase.fit_transform(A)) for A in An] for An in As]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for n_idx, n in enumerate(ns):\n",
    "    for j in range(50):\n",
    "        data.extend([(Xhats_aligned[n_idx][j][i][0], i, n, j, np.sqrt(p)) for i in range(n)])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Xhat\", \"i\", \"n\", \"j\", \"X\"])\n",
    "df[\"abs_diff\"] = np.abs(df[\"Xhat\"] - df[\"X\"])\n",
    "\n",
    "max_pernet = df.groupby([\"n\", \"j\"])[\"abs_diff\"].max().reset_index()\n",
    "max_pernet[\"norm_factor\"] = np.log(max_pernet[\"n\"])**2 / np.sqrt(max_pernet[\"n\"])\n",
    "max_pernet[\"norm_diff\"] = max_pernet[\"abs_diff\"] / max_pernet[\"norm_factor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0766dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df[df[\"j\"] == 0].copy()\n",
    "df_reduced[\"limiting_factor\"] = np.sqrt(df_reduced[\"n\"]) * (df_reduced[\"Xhat\"] - df_reduced[\"X\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
