{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd3e390-986d-494c-a1ff-bd5b96488b81",
   "metadata": {},
   "source": [
    "(appB:mle)=\n",
    "# B.1 The basics of maximum likelihood estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f70d0-be58-44d1-80eb-07ded913c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"svg\"\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "font = {'family' : 'Dejavu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd56873-7d15-4717-9a1f-14c7df2b635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p = np.linspace(.02, .98, num=49)\n",
    "nflips = 10; nheads = 6\n",
    "likelihood = p**(nheads)*(1 - p)**(nflips - nheads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880ab3e-85e4-4157-ad63-9b637e3e31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loglikelihood = nheads*np.log(p) + (nflips - nheads)*np.log(1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb68020-2d44-449a-b810-9caa4e67c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "sns.lineplot(x=p, y=likelihood, ax=axs[0], color=\"black\")\n",
    "axs[0].axvline(.6, color=\"gray\", linestyle=\"--\")\n",
    "axs[0].set(xlabel=\"Bernoulli probability parameter, p\", title=\"(A) Likelihood, $P_{\\\\theta}(x_1, ..., x_{10})$\");\n",
    "\n",
    "sns.lineplot(x=p, y=loglikelihood, ax=axs[1], color=\"black\")\n",
    "axs[1].axvline(.6, color=\"gray\", linestyle=\"--\")\n",
    "axs[1].set(xlabel=\"\", title=\"(B) Log likelihood, $\\\\log P_{\\\\theta}(x_1, ..., x_{10})$\");\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "os.makedirs(\"Figures\", exist_ok=True)\n",
    "fname = \"mle_coin\"\n",
    "if mode != \"png\":\n",
    "    os.makedirs(f\"Figures/{mode:s}\", exist_ok=True)\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "\n",
    "os.makedirs(\"Figures/png\", exist_ok=True)\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf7ba6a-7610-4623-9d7b-40ec8a23ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "# simulation of 1000 values from the N(0,1) distn\n",
    "n = 1000\n",
    "xs = np.random.normal(loc=0, scale=1, size=n)\n",
    "ys = np.random.normal(loc=0, scale=1, size=n)\n",
    "# compute the square\n",
    "xssq = xs**2\n",
    "yssq = ys**2\n",
    "sum_xsq_ysq = xssq + yssq\n",
    "\n",
    "# compute the centers for bin histograms from 0 to maxval in\n",
    "# 30 even bins\n",
    "nbins = 30\n",
    "bincenters = np.linspace(start=0, stop=np.max(sum_xsq_ysq), num=nbins)\n",
    "\n",
    "# compute the pdf of the chi-squared distribution for X^2 + Y^2, which when\n",
    "# X, Y are N(0, 1), is Chi2(2), the chi-squared distn with 2 degrees of freedom\n",
    "dof = 2\n",
    "true_pdf = sp.stats.chi2.pdf(bincenters, dof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48fb96-49dd-4c6a-8845-8d0fc63a3ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.simulations import er_np\n",
    "from graspologic.models import EREstimator\n",
    "\n",
    "n = 10  # number of nodes\n",
    "nsims = 200  # number of networks to simulate\n",
    "p = 0.4\n",
    "\n",
    "As = [er_np(n, p, directed=False, loops=False) for i in range(0, nsims)]  # realizations\n",
    "fit_models = [EREstimator(directed=False, loops=False).fit(A) for A in As]  # fit ER models\n",
    "hatps = [model.p_ for model in fit_models]  # the probability parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e5751-c300-47ef-acae-f87f9a47ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(18, 5))\n",
    "\n",
    "df = DataFrame({\"x\": bincenters, \"y\": true_pdf})\n",
    "sns.histplot(sum_xsq_ysq, bins=30, ax=axs[0], stat = \"density\", color=\"black\")\n",
    "sns.lineplot(x=\"x\", y=\"y\", data=df, ax=axs[0], color=\"#AAAAAA\", linestyle=\"--\", linewidth=4)\n",
    "axs[0].set_xlabel(\"value of $x^2 + y^2$\")\n",
    "axs[0].set_ylabel(\"approximate density\")\n",
    "axs[0].set_title(\"(A) Parametric bootstrap vs true distribution\");\n",
    "\n",
    "sns.histplot(hatps, bins=15, ax=axs[1], stat=\"probability\", color=\"black\")\n",
    "axs[1].set_xlim(0, 1)\n",
    "axs[1].set_ylabel(\"approximate density\")\n",
    "axs[1].axvline(np.mean(hatps), color=\"#AAAAAA\", linestyle=\"--\", linewidth=4)\n",
    "axs[1].text(x=np.mean(hatps) - .32, y=.2, s=\"mean of means\", color=\"#999999\");\n",
    "axs[1].set_title(\"(B) Distribution of $\\\\mathbf{\\\\hat p}_{20}$\")\n",
    "axs[1].set_xlabel(\"Value of estimate of $\\\\hat p_{20}$\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fname = \"mle_param_bootstrap\"\n",
    "if mode != \"png\":\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea33b85-2a26-4372-9d82-5dc647db245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "ns = [8, 16, 32, 64, 128]\n",
    "nsims = 200\n",
    "p = 0.4\n",
    "\n",
    "results = []\n",
    "for n in ns:\n",
    "    for i in range(0, nsims):\n",
    "        A = gp.simulations.er_np(n, p, directed=False, loops=False)\n",
    "        phatni = gp.models.EREstimator(directed=False, loops=False).fit(A).p_\n",
    "        results.append({\"n\": n, \"i\": i, \"phat\": phatni})\n",
    "\n",
    "res_df = DataFrame(results)\n",
    "res_df[\"diff\"] = np.abs(res_df[\"phat\"] - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d29872-ec1f-4c73-8c36-9406794562ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10, 4))\n",
    "\n",
    "sns.lineplot(data=res_df, x=\"n\", y=\"diff\", ax=ax, color=\"black\")\n",
    "ax.set_title(\"Empirical consistency of estimate of $p$\")\n",
    "ax.set_xlabel(\"Number of nodes\")\n",
    "ax.set_ylabel(\"$|\\\\hat p_n - p|$\");\n",
    "\n",
    "fig.tight_layout()\n",
    "fname = \"mle_asy_cons\"\n",
    "if mode != \"png\":\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedb837-83b5-4e99-bad9-4011cb9ed153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
