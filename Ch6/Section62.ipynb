{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a4cd7-32cf-4c61-b072-57b643cce1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"svg\"\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "font = {'family' : 'Dejavu Sans',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6078e7e-1d64-42da-b94f-ccaf8411adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graspologic.simulations import sample_edges\n",
    "from graphbook_code import generate_sbm_pmtx\n",
    "    \n",
    "def academic_pmtx(K, nk=10, return_zs=False):\n",
    "    \"\"\"\n",
    "    Produce probability matrix for academic example.\n",
    "    \"\"\"\n",
    "    n = K*nk\n",
    "    # get the community assignments\n",
    "    zs = np.repeat(np.arange(K)+1, repeats=nk)\n",
    "    # randomly generate proteges and lab leaders\n",
    "    unif_choices = np.random.uniform(size=n)\n",
    "    thetas = np.zeros(n)\n",
    "    # 90% are proteges\n",
    "    thetas[unif_choices > .1] = np.random.beta(1, 5, size=(unif_choices > .1).sum())\n",
    "    # 10% are lab leaders\n",
    "    thetas[unif_choices <= .1] = np.random.beta(2, 1, size=(unif_choices <= .1).sum())\n",
    "    # define block matrix\n",
    "    B = np.full(shape=(K,K), fill_value=0.01)\n",
    "    np.fill_diagonal(B, 1)\n",
    "    # generate probability matrix for SBM\n",
    "    Pp = generate_sbm_pmtx(zs, B)\n",
    "    Theta = np.diag(thetas)\n",
    "    # adjust probability matrix for SBM by degree-corrections\n",
    "    P = Theta @ Pp @ Theta.transpose()\n",
    "    if return_zs:\n",
    "        return P, zs\n",
    "    return P\n",
    "\n",
    "def academic_example(K, nk=10, return_zs=False):\n",
    "    P = academic_pmtx(K, nk=nk, return_zs=return_zs)\n",
    "    if return_zs:\n",
    "        return (sample_edges(P[0]), P[1])\n",
    "    else:\n",
    "        return sample_edges(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c47b5-f482-4243-b24d-41e77deee856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "nrep = 50\n",
    "for K in np.linspace(start=2, stop=128, num=10, dtype=int):\n",
    "    for j in range(nrep):\n",
    "        P = academic_pmtx(K)\n",
    "        n = P.shape[0]\n",
    "        results.append({\"Count\": np.triu(P, k=1).sum(), \"Edges\": \"Expected\", \n",
    "                        \"#Nodes\": n, \"Index\": j})\n",
    "        results.append({\"Count\": n*(n - 1)/2000, \"Edges\": \"Potential/1000\",\n",
    "                        \"#Nodes\": n, \"Index\": j})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df_mean=df.groupby([\"Edges\", \"#Nodes\"])[[\"Count\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577853c9-53c6-4aa3-9333-be13cf09d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = pd.pivot(df_mean.reset_index(), index=\"#Nodes\", columns=\"Edges\", values=\"Count\")\n",
    "# remember normalizing constant of 100 for potential edges\n",
    "df_wide[\"Density\"] = df_wide[\"Expected\"]/(1000*df_wide[\"Potential/1000\"])\n",
    "df_wide = df_wide.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651876ca-473b-4ffa-955f-803d1656dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide[\"Degree\"] = df_wide[\"Density\"]*(df_wide[\"#Nodes\"] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316edaba-a4be-4283-b2c1-a879bcee45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "dash_patterns={\"Expected\": [], \"Potential/100\": (5, 8)}\n",
    "sns.lineplot(data=df_mean, x=\"#Nodes\", y=\"Count\", style=\"Edges\", color=\"black\", ax=axs[0])\n",
    "axs[0].set_title(\"(A) Direct definition of sparsity\")\n",
    "axs[0].plot([0, 440], [int(df_wide[df_wide[\"#Nodes\"] == 440][\"Potential/1000\"])]*2, color=\"#999999\")\n",
    "axs[0].plot([0, 440], [int(df_wide[df_wide[\"#Nodes\"] == 440][\"Expected\"])]*2, color=\"#999999\")\n",
    "axs[0].axvline(x=440, color=\"#999999\")\n",
    "axs[0].set_xlim((0, 1280))\n",
    "axs[0].set_ylim((0, 1000))\n",
    "axs[0].set_ylabel(\"Average count\")\n",
    "axs[0].annotate(\"Potential = {:d}\".format(int(1000*df_wide[df_wide[\"#Nodes\"] == 440][\"Potential/1000\"])), xytext=(550, 100),\n",
    "                xy=(440, df_wide[df_wide[\"#Nodes\"] == 440][\"Potential/1000\"]), fontsize=14, arrowprops={\"arrowstyle\": \"->\"})\n",
    "axs[0].annotate(\"Expected = {:.1f}\".format(float(df_wide[df_wide[\"#Nodes\"] == 440][\"Expected\"])), xytext=(50, 200),\n",
    "                xy=(440, df_wide[df_wide[\"#Nodes\"] == 440][\"Expected\"]), fontsize=14, arrowprops={\"arrowstyle\": \"->\"})\n",
    "\n",
    "for line, category in zip(axs[0].lines, dash_patterns.keys()):\n",
    "    if dash_patterns[category]:  # Check if there's a dash pattern for the category\n",
    "        line.set_dashes(dash_patterns[category])\n",
    "    else:\n",
    "        line.set_linestyle('-')\n",
    "\n",
    "sns.lineplot(data=df_wide, x=\"#Nodes\", y=\"Density\", color=\"black\", ax=axs[1])\n",
    "axs[1].set_title(\"(B) Density and sparsity\")\n",
    "axs[1].annotate(\"Converging to $0$\", xy=(1000, .003), xytext=(500, .01), arrowprops={\"arrowstyle\": \"->\"})\n",
    "axs[1].set_ylabel(\"Average density\")\n",
    "\n",
    "sns.lineplot(data=df_wide, x=\"#Nodes\", y=\"Degree\", color=\"black\", ax=axs[2])\n",
    "axs[2].set_title(\"(C) Degree and sparsity\")\n",
    "axs[2].plot([0, 1280], [0, 1280*.001], color=\"#999999\", linestyle=\"--\", dashes=(5, 8))\n",
    "axs[2].set_ylabel(\"Average degree\")\n",
    "axs[2].annotate(\"$y = n \\\\cdot \\\\epsilon$\", xy=(600, 1), color=\"#999999\")\n",
    "# axs[2].annotate(\"Average degree \\nfalling relative line\\n proportional to $n$\", xy=(200, 1.0), xytext=(500, .01), arrowprops={\"arrowstyle\": \"->\"})\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "os.makedirs(\"Figures\", exist_ok=True)\n",
    "fname = \"sparsity\"\n",
    "if mode != \"png\":\n",
    "    os.makedirs(f\"Figures/{mode:s}\", exist_ok=True)\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "\n",
    "os.makedirs(\"Figures/png\", exist_ok=True)\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15005aa7-5fa0-4b38-9945-2136dcb7137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10; nk = 100\n",
    "np.random.seed(0)\n",
    "P, zs = academic_pmtx(K, nk=nk, return_zs=True)\n",
    "A = sample_edges(P)\n",
    "\n",
    "print(f\"# Non-zero entries: {np.triu(A).sum().astype(int)}\")  \n",
    "# Non-zero entries: 2390\n",
    "\n",
    "print(f\"# Number of entries: {A.size}\")  \n",
    "# Number of entries: 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7f176-f66e-4982-b8bb-c02a14e0518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size in KB: {A.nbytes/1000:.3f} KB\")\n",
    "# Size in KB: 8000.000 KB\n",
    "\n",
    "B = A.astype(np.uint8)\n",
    "print(f\"Size in KB: {B.nbytes/1000:.3f} KB\")\n",
    "# Size in KB: 1000.000 KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9066ce9-34b5-4d93-aaf7-7d31a58a58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "Btriu = sparse.triu(B)\n",
    "print(f\"Size in KB: {Btriu.data.size/1000:.3f} KB\")\n",
    "# Size in KB: 2.390 KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d21f8-1475-4427-9721-ca680e4ad6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Btriu\n",
    "# <1000x1000 sparse matrix of type '<class 'numpy.uint8'>'\n",
    "#     with 2390 stored elements in COOrdinate format>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d44e7-7a29-4004-aa0d-05878f6c3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graspologic.utils import symmetrize\n",
    "\n",
    "# cast the sparse matrix back to a dense matrix,\n",
    "# and then triu symmetrize with graspologic\n",
    "A_new = symmetrize(Btriu.todense(), method=\"triu\")\n",
    "np.array_equal(A_new, A)  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eccfc3-a295-4476-8767-9aae1cd661c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy as sp\n",
    "\n",
    "# a naive full svd on the dense matrix\n",
    "timestart = time.time()\n",
    "U, S, Vh = sp.linalg.svd(A)\n",
    "Xhat = U[:, 0:10] @ np.diag(np.sqrt(S[0:10]))\n",
    "timeend = time.time()\n",
    "print(f\"Naive approach: {timeend - timestart:3f} seconds\")\n",
    "# we get about 0.55 seconds\n",
    "\n",
    "# a sparse svd on the sparse matrix\n",
    "Acoo = sparse.coo_array(A)\n",
    "timestart = time.time()\n",
    "U, S, Vh = sp.sparse.linalg.svds(Acoo, k=10)\n",
    "Xhat = U @ np.diag(np.sqrt(S))\n",
    "timeend = time.time()\n",
    "print(f\"Sparse approach: {timeend-timestart:3f} seconds\")\n",
    "# we get about .09 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315e1b9-d098-4e1f-ad59-57cbebc3bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = A.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65abb9-a570-46ff-8cc5-757e43424377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphbook_code import heatmap\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "heatmap(P, ax=axs[0], xtitle=\"Node\", vmin=0, vmax=1, inner_hier_labels=zs)\n",
    "heatmap(A.astype(int), ax=axs[1], xtitle=\"Node\", inner_hier_labels=zs)\n",
    "axs[0].set_title(\"(A) Probability matrix\", pad=60)\n",
    "axs[1].set_title(\"(B) Adjacency matrix\", pad=60)\n",
    "fig.tight_layout()\n",
    "\n",
    "sns.histplot(degrees, ax=axs[2], color=\"black\")\n",
    "axs[2].set_xlabel(\"Node degree\")\n",
    "axs[2].set_title(\"(C) Degree histogram\", pad=34)\n",
    "\n",
    "fname = \"eigenspoke_ex\"\n",
    "if mode != \"png\":\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9721f-2e72-4426-8dd7-fc03ac9c4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from graspologic.utils import to_laplacian\n",
    "from graspologic.plot import pairplot\n",
    "\n",
    "# use sparse svd, so that we don't need to compute\n",
    "# 1000 singular vectors and can just calculate the top 10\n",
    "U, S, Vh = sp.sparse.linalg.svds(to_laplacian(A), k=10, random_state=123)\n",
    "# plot the first 4\n",
    "fig = pairplot(U[:,0:4], labels=zs, title=\"(A) Eigenspokes in the Laplacian\", legend_name=\"Community\")\n",
    "\n",
    "fname = \"eigenspokesa\"\n",
    "if mode != \"png\":\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237dd75-b88d-480f-a301-c50749755863",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vh = sp.sparse.linalg.svds(A, k=10, random_state=123)\n",
    "# plot the first 4\n",
    "fig = pairplot(U[:,0:4], labels=zs, title=\"(B) Eigenspokes in the adjacency matrix\", legend_name=\"Community\")\n",
    "\n",
    "fname = \"eigenspokesb\"\n",
    "if mode != \"png\":\n",
    "    fig.savefig(f\"Figures/{mode:s}/{fname:s}.{mode:s}\")\n",
    "\n",
    "fig.savefig(f\"Figures/png/{fname:s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4f6e1-dd5c-4492-9b7e-2b132b5b192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Expected edges: {:.2f}\".format(np.triu(P).sum()))\n",
    "# Expected edges: 2446.18\n",
    "print(\"# True edges: {:d}\".format(np.triu(A).sum().astype(int)))\n",
    "# True edges: 2390\n",
    "print(\"# Potential edges: {:d}\".format(int(K*nk*(K*nk - 1)/2)))\n",
    "# Potential edges: 499500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f3c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
